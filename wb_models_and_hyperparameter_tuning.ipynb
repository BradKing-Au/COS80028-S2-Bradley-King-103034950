{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b18ec49",
   "metadata": {
    "id": "a6c6eec7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf2c322",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6c91aec",
    "outputId": "f8e0b955-61aa-412e-f486-0912afaf9174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stellargraph\n",
      "  Downloading stellargraph-1.2.1-py3-none-any.whl (435 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |▊                               | 10 kB 17.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 20 kB 23.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 30 kB 23.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 40 kB 18.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 51 kB 14.0 MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 61 kB 12.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 71 kB 12.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 81 kB 13.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 92 kB 13.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 102 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 112 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 122 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 133 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 143 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 153 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 163 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 174 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 184 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 194 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 204 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 215 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 225 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 235 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 245 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 256 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 266 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 276 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 286 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 296 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 307 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 317 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 327 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 337 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 348 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 358 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 368 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 378 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 389 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 399 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 409 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 419 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 430 kB 10.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 435 kB 10.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (1.1.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (0.22.2.post1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (3.2.2)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (2.6.3)\n",
      "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (2.6.0)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (3.6.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->stellargraph) (5.2.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->stellargraph) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->stellargraph) (2018.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->stellargraph) (1.0.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.3.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.6.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.17.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.12)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.41.0)\n",
      "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.6.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.6.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.4.0)\n",
      "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (5.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.7.4.3)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.6.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.12.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.37.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.12.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.1.0->stellargraph) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (0.4.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (57.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (0.6.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (4.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->stellargraph) (3.6.0)\n",
      "Installing collected packages: stellargraph\n",
      "Successfully installed stellargraph-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install stellargraph #will be already installed if running on a local virtual environment. Necessary if using google colab\n",
    "\n",
    "import stellargraph as sg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac33e1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "b88T2wGWMhP6",
    "outputId": "85c52888-c43c-471b-fb3c-d0333570807d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-fd48cfc2-7c3c-40a5-94f4-13ccdacb653c\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-fd48cfc2-7c3c-40a5-94f4-13ccdacb653c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving wbdataset.csv to wbdataset.csv\n"
     ]
    }
   ],
   "source": [
    "#comment out this cell if not using google Colab\n",
    "\n",
    "try:\n",
    "    os.makedirs('clean_data')\n",
    "except OSError:\n",
    "    pass\n",
    "%cd clean_data\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4773cbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "b17e6099",
    "outputId": "feb42f44-afe8-483b-f3f7-3b4e390e88df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col0,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col1,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col2,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col3,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col4,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col5,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col6,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col7{\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col1,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col0,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col7,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col6{\n",
       "            background-color:  #bcd2f7;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col2,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col0{\n",
       "            background-color:  #c73635;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col3,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col0,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col7,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col4{\n",
       "            background-color:  #afcafc;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col4,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col0,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col6,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col4{\n",
       "            background-color:  #df634e;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col5,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col0{\n",
       "            background-color:  #90b2fe;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col6,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col0{\n",
       "            background-color:  #cf453c;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col7,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col5,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col4,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col0{\n",
       "            background-color:  #9ebeff;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col2,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col1{\n",
       "            background-color:  #c1d4f4;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col3,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col1{\n",
       "            background-color:  #f7ac8e;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col4,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col1{\n",
       "            background-color:  #c3d5f4;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col5,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col1{\n",
       "            background-color:  #f5c4ac;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col6,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col1{\n",
       "            background-color:  #bfd3f6;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col7,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col1{\n",
       "            background-color:  #f1cdba;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col3,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col2,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col6,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col3{\n",
       "            background-color:  #b9d0f9;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col4,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col2{\n",
       "            background-color:  #dd5f4b;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col5,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col2{\n",
       "            background-color:  #92b4fe;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col6,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col2{\n",
       "            background-color:  #cc403a;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col7,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col2{\n",
       "            background-color:  #a2c1ff;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col4,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col3{\n",
       "            background-color:  #bed2f6;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col5,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col3{\n",
       "            background-color:  #f7b599;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col7,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col3{\n",
       "            background-color:  #f6bda2;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col6,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col5{\n",
       "            background-color:  #97b8ff;\n",
       "            color:  #000000;\n",
       "        }#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col7,#T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col5{\n",
       "            background-color:  #f7b99e;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >063Volume</th>        <th class=\"col_heading level0 col1\" >063Speed</th>        <th class=\"col_heading level0 col2\" >051Volume</th>        <th class=\"col_heading level0 col3\" >051Speed</th>        <th class=\"col_heading level0 col4\" >031Volume</th>        <th class=\"col_heading level0 col5\" >031Speed</th>        <th class=\"col_heading level0 col6\" >003Volume</th>        <th class=\"col_heading level0 col7\" >003Speed</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >063Volume</th>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col1\" class=\"data row0 col1\" >-0.22</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0.90</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col3\" class=\"data row0 col3\" >-0.30</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col4\" class=\"data row0 col4\" >0.74</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col5\" class=\"data row0 col5\" >-0.48</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col6\" class=\"data row0 col6\" >0.85</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row0_col7\" class=\"data row0 col7\" >-0.40</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >063Speed</th>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col0\" class=\"data row1 col0\" >-0.22</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col2\" class=\"data row1 col2\" >-0.19</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col3\" class=\"data row1 col3\" >0.40</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col4\" class=\"data row1 col4\" >-0.19</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col5\" class=\"data row1 col5\" >0.26</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col6\" class=\"data row1 col6\" >-0.20</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row1_col7\" class=\"data row1 col7\" >0.19</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >051Volume</th>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col0\" class=\"data row2 col0\" >0.90</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col1\" class=\"data row2 col1\" >-0.19</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col3\" class=\"data row2 col3\" >-0.24</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col4\" class=\"data row2 col4\" >0.75</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col5\" class=\"data row2 col5\" >-0.47</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col6\" class=\"data row2 col6\" >0.86</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row2_col7\" class=\"data row2 col7\" >-0.38</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >051Speed</th>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col0\" class=\"data row3 col0\" >-0.30</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0.40</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col2\" class=\"data row3 col2\" >-0.24</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col4\" class=\"data row3 col4\" >-0.21</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col5\" class=\"data row3 col5\" >0.35</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col6\" class=\"data row3 col6\" >-0.24</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row3_col7\" class=\"data row3 col7\" >0.30</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >031Volume</th>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col0\" class=\"data row4 col0\" >0.74</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col1\" class=\"data row4 col1\" >-0.19</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col2\" class=\"data row4 col2\" >0.75</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col3\" class=\"data row4 col3\" >-0.21</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col5\" class=\"data row4 col5\" >-0.40</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col6\" class=\"data row4 col6\" >0.74</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row4_col7\" class=\"data row4 col7\" >-0.30</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >031Speed</th>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col0\" class=\"data row5 col0\" >-0.48</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col1\" class=\"data row5 col1\" >0.26</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col2\" class=\"data row5 col2\" >-0.47</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col3\" class=\"data row5 col3\" >0.35</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col4\" class=\"data row5 col4\" >-0.40</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col6\" class=\"data row5 col6\" >-0.44</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row5_col7\" class=\"data row5 col7\" >0.32</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >003Volume</th>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col0\" class=\"data row6 col0\" >0.85</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col1\" class=\"data row6 col1\" >-0.20</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col2\" class=\"data row6 col2\" >0.86</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col3\" class=\"data row6 col3\" >-0.24</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col4\" class=\"data row6 col4\" >0.74</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col5\" class=\"data row6 col5\" >-0.44</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row6_col7\" class=\"data row6 col7\" >-0.23</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >003Speed</th>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col0\" class=\"data row7 col0\" >-0.40</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col1\" class=\"data row7 col1\" >0.19</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col2\" class=\"data row7 col2\" >-0.38</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col3\" class=\"data row7 col3\" >0.30</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col4\" class=\"data row7 col4\" >-0.30</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col5\" class=\"data row7 col5\" >0.32</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col6\" class=\"data row7 col6\" >-0.23</td>\n",
       "                        <td id=\"T_18ce69cc_3600_11ec_a8c6_0242ac1c0002row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdd6b536310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"clean_data/wbdataset.csv\")\n",
    "dataset.drop(['Time','Date'], axis = 1, inplace = True)\n",
    "corrmatrix = dataset.corr() \n",
    "\n",
    "corrmatrix.style.background_gradient(cmap='coolwarm',vmin = -1, vmax = 1).set_precision(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da29a33",
   "metadata": {
    "id": "WwckNZvgdGgd"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs('model_performances')\n",
    "except OSError:\n",
    "    pass\n",
    "corrmatrix.to_csv('model_performances/wbcorrmatrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307202a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMTsdrybMfvr",
    "outputId": "f575af7e-c41f-4940-f352-45e228911bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#checking if GPU acceleration is active. If GPU device isnt found, import and run on collab\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55031a10",
   "metadata": {
    "id": "23fbffb3"
   },
   "outputs": [],
   "source": [
    "\n",
    "min_max_scaler = MinMaxScaler()#saving sklearns minmaxscaler as an object so it can be used to reverse any transformations later\n",
    "scaled_dataset = pd.DataFrame(min_max_scaler.fit_transform(dataset))#scaling each column of the dataset so that all values are between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb15b102",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cf046c3",
    "outputId": "dc834e8e-1cbb-46c1-ce20-bad0888393b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   063Volume  063Speed  051Volume  ...  031Speed  003Volume  003Speed\n",
      "0          3    97.000          7  ...    100.00         13     91.33\n",
      "1          3    95.750          8  ...     95.33          4     79.50\n",
      "2          4   108.170          6  ...     95.25         10     92.71\n",
      "3          0   103.085          4  ...     88.04          7     87.63\n",
      "4          1    98.000         13  ...    102.50          4     89.25\n",
      "\n",
      "[5 rows x 8 columns]\n",
      "          0         1         2  ...         5         6         7\n",
      "0  0.027273  0.510638  0.046980  ...  0.459459  0.082803  0.622966\n",
      "1  0.027273  0.503989  0.053691  ...  0.427905  0.025478  0.541379\n",
      "2  0.036364  0.570053  0.040268  ...  0.427365  0.063694  0.632483\n",
      "3  0.000000  0.543005  0.026846  ...  0.378649  0.044586  0.597448\n",
      "4  0.009091  0.515957  0.087248  ...  0.476351  0.025478  0.608621\n",
      "\n",
      "[5 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head())\n",
    "print(scaled_dataset.head())#testing transformation was sucessful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ad5b14b",
   "metadata": {
    "id": "43eda98d"
   },
   "outputs": [],
   "source": [
    "#This function is taken from the StellarGraph documentation https://stellargraph.readthedocs.io/en/stable/demos/time-series/gcn-lstm-time-series.html\n",
    "#Annotation provided by Bradley King \n",
    "#Modified to support time scale on the verticle axis instead of horizontal, transposes results to timescale on horizontal axis to support model format\n",
    "#Modified to include a validation split as well as training/testing splits\n",
    "\n",
    "train_split = 0.7 #portion of data for training\n",
    "val_split = .15   #portion of data for testing\n",
    "def split_time_data(data,train_portion,val_portion): # function for splitting data. recieves arugments for data, portion for training and portion for validation\n",
    "    time_scale = data.shape[0]\n",
    "    train_length = int(time_scale * train_portion)\n",
    "    train_data=np.array(data.iloc[ :train_length,:])\n",
    "    train_data_t = train_data.transpose()\n",
    "    val_length = int(time_scale*val_portion)\n",
    "    val_data = np.array(data.iloc[train_length:train_length+val_length,:])\n",
    "    val_data_t = val_data.transpose()\n",
    "    test_data=np.array(data.iloc[ train_length+val_length:,:])\n",
    "    test_data_t=test_data.transpose()\n",
    "    return train_data, val_data, test_data,train_data_t,val_data_t,test_data_t # returns training split, validation split, testing split and transposed versions of each split to suit model formatting requirements downstream\n",
    "\n",
    "\n",
    "train_data,val_data, test_data,train_data_t,val_data_t,test_data_t = split_time_data(scaled_dataset, train_split,val_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df4462",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bb896d3",
    "outputId": "e8c31655-f562-4173-9873-4cf6fc3c62e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66240, 8)\n",
      "Train data: (46368, 8)\n",
      "Val data: (9936, 8)\n",
      "Test data: (9936, 8)\n",
      "Train data transposed: (8, 46368)\n",
      "Val data transposed: (8, 9936)\n",
      "Test data transposed: (8, 9936)\n"
     ]
    }
   ],
   "source": [
    "#checking data shapes and formatting \n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "print(\"Train data:\", train_data.shape)\n",
    "print(\"Val data:\", val_data.shape)\n",
    "print(\"Test data:\", test_data.shape)\n",
    "print(\"Train data transposed:\", train_data_t.shape)\n",
    "print(\"Val data transposed:\", val_data_t.shape)\n",
    "print(\"Test data transposed:\", test_data_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "743bef01",
   "metadata": {
    "id": "1a9124fe"
   },
   "outputs": [],
   "source": [
    "seq_len = 10 #length of data used for the prediction, currently using the last 10 mins of data\n",
    "pre_len = 30 # distance of prediction, currently predicting speeds and volumes 30 mins from now\n",
    "\n",
    "#This function is taken from the StellarGraph documentation https://stellargraph.readthedocs.io/en/stable/demos/time-series/gcn-lstm-time-series.html\n",
    "#Annotation provided by Bradley King \n",
    "#Function modified to accept validation splits as well as training and testing\n",
    "def sequence_data_preparation(seq_len, pre_len, train_data, val_data, test_data):\n",
    "    trainX, trainY, valX,valY,testX, testY = [], [], [], [],[],[]\n",
    "\n",
    "    for i in range(train_data.shape[1] - int(seq_len + pre_len - 1)):\n",
    "        a = train_data[:, i : i + seq_len + pre_len] # grabbing a slice of the datafrom from time - sequence length to time + prediction length\n",
    "        trainX.append(a[:, :seq_len]) # grab the first 10 columns, this is the prediction data\n",
    "        trainY.append(a[:, -1]) # grab the last column in the slice, this is the target data\n",
    "\n",
    "    for i in range(val_data.shape[1] - int(seq_len + pre_len - 1)):\n",
    "        c = val_data[:, i : i + seq_len + pre_len] # grabbing a slice of the datafrom from time - sequence length to time + prediction length\n",
    "        valX.append(c[:, :seq_len]) # grab the first 10 columns, this is the prediction data\n",
    "        valY.append(c[:, -1]) # grab the last column in the slice, this is the target data\n",
    "\n",
    "    # do the same process for the test data\n",
    "    for i in range(test_data.shape[1] - int(seq_len + pre_len - 1)):\n",
    "        b = test_data[:, i : i + seq_len + pre_len]\n",
    "        testX.append(b[:, :seq_len])\n",
    "        testY.append(b[:, -1])\n",
    "    #when appending use lists, its easier computationally. Convert to numpy array at the end\n",
    "    trainX = np.array(trainX) \n",
    "    trainY = np.array(trainY)\n",
    "    valX = np.array(valX)\n",
    "    valY=np.array(valY)\n",
    "    testX = np.array(testX)\n",
    "    testY = np.array(testY)\n",
    "\n",
    "    return trainX, trainY, valX,valY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bfd9abb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34eadf3f",
    "outputId": "69a10016-0833-4c78-ad83-c2e2b57c295e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46329, 8, 10)\n",
      "(46329, 8)\n",
      "(9897, 8, 10)\n",
      "(9897, 8)\n",
      "(9897, 8, 10)\n",
      "(9897, 8)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY,valX,valY, testX, testY = sequence_data_preparation(\n",
    "    seq_len, pre_len, train_data_t, val_data_t,test_data_t) #creating model features and target attributes\n",
    "\n",
    "#testing feature shapes\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(valX.shape)\n",
    "print(valY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "900e156c",
   "metadata": {
    "id": "69109e7a"
   },
   "outputs": [],
   "source": [
    "from stellargraph.layer import GCN_LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c78a1d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eff85a3e",
    "outputId": "8e560059-2bc1-4609-c992-bf43a53a0d9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=corrmatrix,\n",
    "    gc_layer_sizes=[16, 10],\n",
    "    gc_activations=[\"relu\", \"relu\"],\n",
    "    lstm_layer_sizes=[200, 200],\n",
    "    lstm_activations=[\"tanh\", \"tanh\"],\n",
    ") # defining lstm model, using default parameters provided by StellarGraphs GCN_LSTM technical demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7214926",
   "metadata": {
    "id": "0e6e3d3b"
   },
   "outputs": [],
   "source": [
    "x_input, x_output = gcn_lstm.in_out_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aad30fde",
   "metadata": {
    "id": "a22c21ac"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=x_input, outputs=x_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04042279",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t66LmyOa-nT7",
    "outputId": "a47ed699-1b7a-46fc-ee67-c4c266b51cbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "232/232 [==============================] - 13s 21ms/step - loss: 0.1345 - mse: 0.0334 - val_loss: 0.0936 - val_mse: 0.0194\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.1060 - mse: 0.0215 - val_loss: 0.0847 - val_mse: 0.0159\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0896 - mse: 0.0160 - val_loss: 0.0706 - val_mse: 0.0117\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0736 - mse: 0.0118 - val_loss: 0.0624 - val_mse: 0.0110\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0693 - mse: 0.0111 - val_loss: 0.0612 - val_mse: 0.0108\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0676 - mse: 0.0108 - val_loss: 0.0609 - val_mse: 0.0107\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0664 - mse: 0.0106 - val_loss: 0.0600 - val_mse: 0.0106\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0656 - mse: 0.0105 - val_loss: 0.0597 - val_mse: 0.0105\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0647 - mse: 0.0103 - val_loss: 0.0591 - val_mse: 0.0104\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0641 - mse: 0.0102 - val_loss: 0.0591 - val_mse: 0.0104\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0636 - mse: 0.0101 - val_loss: 0.0586 - val_mse: 0.0103\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0631 - mse: 0.0100 - val_loss: 0.0585 - val_mse: 0.0102\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0626 - mse: 0.0099 - val_loss: 0.0582 - val_mse: 0.0102\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0623 - mse: 0.0099 - val_loss: 0.0586 - val_mse: 0.0102\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0619 - mse: 0.0098 - val_loss: 0.0580 - val_mse: 0.0101\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0616 - mse: 0.0097 - val_loss: 0.0581 - val_mse: 0.0100\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0612 - mse: 0.0096 - val_loss: 0.0579 - val_mse: 0.0100\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0609 - mse: 0.0096 - val_loss: 0.0578 - val_mse: 0.0099\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0606 - mse: 0.0095 - val_loss: 0.0577 - val_mse: 0.0099\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0603 - mse: 0.0094 - val_loss: 0.0574 - val_mse: 0.0098\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0600 - mse: 0.0094 - val_loss: 0.0574 - val_mse: 0.0099\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0598 - mse: 0.0093 - val_loss: 0.0578 - val_mse: 0.0100\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0595 - mse: 0.0093 - val_loss: 0.0570 - val_mse: 0.0098\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0592 - mse: 0.0092 - val_loss: 0.0576 - val_mse: 0.0098\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0589 - mse: 0.0091 - val_loss: 0.0568 - val_mse: 0.0097\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0587 - mse: 0.0091 - val_loss: 0.0570 - val_mse: 0.0096\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0584 - mse: 0.0090 - val_loss: 0.0564 - val_mse: 0.0095\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0582 - mse: 0.0089 - val_loss: 0.0571 - val_mse: 0.0096\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0579 - mse: 0.0089 - val_loss: 0.0570 - val_mse: 0.0096\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0576 - mse: 0.0088 - val_loss: 0.0571 - val_mse: 0.0095\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0574 - mse: 0.0087 - val_loss: 0.0565 - val_mse: 0.0094\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0572 - mse: 0.0086 - val_loss: 0.0566 - val_mse: 0.0094\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0570 - mse: 0.0086 - val_loss: 0.0564 - val_mse: 0.0094\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0567 - mse: 0.0085 - val_loss: 0.0563 - val_mse: 0.0094\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0566 - mse: 0.0085 - val_loss: 0.0563 - val_mse: 0.0093\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0564 - mse: 0.0085 - val_loss: 0.0561 - val_mse: 0.0093\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0561 - mse: 0.0084 - val_loss: 0.0560 - val_mse: 0.0092\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0559 - mse: 0.0084 - val_loss: 0.0558 - val_mse: 0.0092\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0558 - mse: 0.0083 - val_loss: 0.0557 - val_mse: 0.0091\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0556 - mse: 0.0083 - val_loss: 0.0560 - val_mse: 0.0092\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0555 - mse: 0.0083 - val_loss: 0.0557 - val_mse: 0.0091\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0554 - mse: 0.0083 - val_loss: 0.0558 - val_mse: 0.0091\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0553 - mse: 0.0083 - val_loss: 0.0560 - val_mse: 0.0092\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0552 - mse: 0.0083 - val_loss: 0.0558 - val_mse: 0.0092\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0550 - mse: 0.0082 - val_loss: 0.0560 - val_mse: 0.0092\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0549 - mse: 0.0082 - val_loss: 0.0556 - val_mse: 0.0091\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0548 - mse: 0.0082 - val_loss: 0.0556 - val_mse: 0.0091\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0547 - mse: 0.0082 - val_loss: 0.0555 - val_mse: 0.0090\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0545 - mse: 0.0081 - val_loss: 0.0556 - val_mse: 0.0091\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0545 - mse: 0.0081 - val_loss: 0.0556 - val_mse: 0.0091\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0544 - mse: 0.0081 - val_loss: 0.0555 - val_mse: 0.0091\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0543 - mse: 0.0081 - val_loss: 0.0554 - val_mse: 0.0090\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0542 - mse: 0.0081 - val_loss: 0.0551 - val_mse: 0.0090\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0541 - mse: 0.0081 - val_loss: 0.0552 - val_mse: 0.0089\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0540 - mse: 0.0081 - val_loss: 0.0555 - val_mse: 0.0090\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0539 - mse: 0.0080 - val_loss: 0.0550 - val_mse: 0.0088\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0538 - mse: 0.0080 - val_loss: 0.0553 - val_mse: 0.0090\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0538 - mse: 0.0080 - val_loss: 0.0551 - val_mse: 0.0089\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0537 - mse: 0.0080 - val_loss: 0.0548 - val_mse: 0.0088\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0536 - mse: 0.0080 - val_loss: 0.0550 - val_mse: 0.0089\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0536 - mse: 0.0080 - val_loss: 0.0546 - val_mse: 0.0088\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0534 - mse: 0.0079 - val_loss: 0.0551 - val_mse: 0.0089\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0533 - mse: 0.0079 - val_loss: 0.0548 - val_mse: 0.0088\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0533 - mse: 0.0079 - val_loss: 0.0550 - val_mse: 0.0089\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0532 - mse: 0.0079 - val_loss: 0.0546 - val_mse: 0.0088\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0532 - mse: 0.0079 - val_loss: 0.0548 - val_mse: 0.0088\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0531 - mse: 0.0079 - val_loss: 0.0550 - val_mse: 0.0089\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0530 - mse: 0.0079 - val_loss: 0.0548 - val_mse: 0.0089\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0529 - mse: 0.0078 - val_loss: 0.0549 - val_mse: 0.0088\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0529 - mse: 0.0078 - val_loss: 0.0548 - val_mse: 0.0088\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0529 - mse: 0.0078 - val_loss: 0.0546 - val_mse: 0.0088\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0528 - mse: 0.0078 - val_loss: 0.0546 - val_mse: 0.0087\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0527 - mse: 0.0078 - val_loss: 0.0545 - val_mse: 0.0087\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0527 - mse: 0.0078 - val_loss: 0.0545 - val_mse: 0.0087\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0526 - mse: 0.0078 - val_loss: 0.0543 - val_mse: 0.0087\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0525 - mse: 0.0077 - val_loss: 0.0544 - val_mse: 0.0087\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0525 - mse: 0.0077 - val_loss: 0.0546 - val_mse: 0.0086\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0524 - mse: 0.0077 - val_loss: 0.0543 - val_mse: 0.0087\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0524 - mse: 0.0077 - val_loss: 0.0542 - val_mse: 0.0086\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0523 - mse: 0.0077 - val_loss: 0.0543 - val_mse: 0.0086\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0523 - mse: 0.0077 - val_loss: 0.0545 - val_mse: 0.0087\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0522 - mse: 0.0077 - val_loss: 0.0542 - val_mse: 0.0085\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0522 - mse: 0.0077 - val_loss: 0.0541 - val_mse: 0.0086\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0521 - mse: 0.0077 - val_loss: 0.0541 - val_mse: 0.0086\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0521 - mse: 0.0076 - val_loss: 0.0540 - val_mse: 0.0085\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0521 - mse: 0.0076 - val_loss: 0.0543 - val_mse: 0.0086\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0521 - mse: 0.0076 - val_loss: 0.0538 - val_mse: 0.0085\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0519 - mse: 0.0076 - val_loss: 0.0544 - val_mse: 0.0086\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0519 - mse: 0.0076 - val_loss: 0.0539 - val_mse: 0.0085\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0519 - mse: 0.0076 - val_loss: 0.0537 - val_mse: 0.0085\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0519 - mse: 0.0076 - val_loss: 0.0540 - val_mse: 0.0085\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0519 - mse: 0.0076 - val_loss: 0.0539 - val_mse: 0.0085\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0518 - mse: 0.0076 - val_loss: 0.0541 - val_mse: 0.0085\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0517 - mse: 0.0076 - val_loss: 0.0539 - val_mse: 0.0085\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0518 - mse: 0.0076 - val_loss: 0.0535 - val_mse: 0.0084\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0517 - mse: 0.0076 - val_loss: 0.0537 - val_mse: 0.0084\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0517 - mse: 0.0075 - val_loss: 0.0537 - val_mse: 0.0084\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0516 - mse: 0.0075 - val_loss: 0.0540 - val_mse: 0.0085\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0516 - mse: 0.0075 - val_loss: 0.0539 - val_mse: 0.0085\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0515 - mse: 0.0075 - val_loss: 0.0535 - val_mse: 0.0084\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0515 - mse: 0.0075 - val_loss: 0.0535 - val_mse: 0.0084\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0515 - mse: 0.0075 - val_loss: 0.0539 - val_mse: 0.0084\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0515 - mse: 0.0075 - val_loss: 0.0534 - val_mse: 0.0083\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0515 - mse: 0.0075 - val_loss: 0.0536 - val_mse: 0.0084\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0513 - mse: 0.0075 - val_loss: 0.0536 - val_mse: 0.0083\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0513 - mse: 0.0075 - val_loss: 0.0537 - val_mse: 0.0084\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0513 - mse: 0.0075 - val_loss: 0.0538 - val_mse: 0.0084\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0513 - mse: 0.0075 - val_loss: 0.0538 - val_mse: 0.0084\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0513 - mse: 0.0074 - val_loss: 0.0533 - val_mse: 0.0082\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0513 - mse: 0.0074 - val_loss: 0.0533 - val_mse: 0.0083\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0512 - mse: 0.0074 - val_loss: 0.0535 - val_mse: 0.0083\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0512 - mse: 0.0074 - val_loss: 0.0536 - val_mse: 0.0084\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0511 - mse: 0.0074 - val_loss: 0.0536 - val_mse: 0.0083\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0511 - mse: 0.0074 - val_loss: 0.0533 - val_mse: 0.0082\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0510 - mse: 0.0074 - val_loss: 0.0538 - val_mse: 0.0084\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0511 - mse: 0.0074 - val_loss: 0.0533 - val_mse: 0.0083\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0510 - mse: 0.0074 - val_loss: 0.0534 - val_mse: 0.0083\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0510 - mse: 0.0074 - val_loss: 0.0533 - val_mse: 0.0082\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0510 - mse: 0.0074 - val_loss: 0.0536 - val_mse: 0.0083\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0510 - mse: 0.0074 - val_loss: 0.0533 - val_mse: 0.0083\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0510 - mse: 0.0074 - val_loss: 0.0536 - val_mse: 0.0083\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0509 - mse: 0.0073 - val_loss: 0.0534 - val_mse: 0.0083\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0509 - mse: 0.0073 - val_loss: 0.0531 - val_mse: 0.0082\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0508 - mse: 0.0073 - val_loss: 0.0530 - val_mse: 0.0081\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0508 - mse: 0.0073 - val_loss: 0.0532 - val_mse: 0.0083\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0509 - mse: 0.0073 - val_loss: 0.0533 - val_mse: 0.0083\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0508 - mse: 0.0073 - val_loss: 0.0528 - val_mse: 0.0081\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0508 - mse: 0.0073 - val_loss: 0.0531 - val_mse: 0.0082\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0508 - mse: 0.0073 - val_loss: 0.0527 - val_mse: 0.0081\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0507 - mse: 0.0073 - val_loss: 0.0531 - val_mse: 0.0082\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0507 - mse: 0.0073 - val_loss: 0.0533 - val_mse: 0.0083\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0506 - mse: 0.0073 - val_loss: 0.0530 - val_mse: 0.0081\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0507 - mse: 0.0073 - val_loss: 0.0531 - val_mse: 0.0081\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0506 - mse: 0.0073 - val_loss: 0.0529 - val_mse: 0.0081\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0506 - mse: 0.0073 - val_loss: 0.0531 - val_mse: 0.0082\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0506 - mse: 0.0073 - val_loss: 0.0530 - val_mse: 0.0081\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0506 - mse: 0.0073 - val_loss: 0.0529 - val_mse: 0.0081\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0505 - mse: 0.0072 - val_loss: 0.0529 - val_mse: 0.0081\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0505 - mse: 0.0073 - val_loss: 0.0528 - val_mse: 0.0081\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0505 - mse: 0.0072 - val_loss: 0.0529 - val_mse: 0.0081\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0505 - mse: 0.0072 - val_loss: 0.0530 - val_mse: 0.0081\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0504 - mse: 0.0072 - val_loss: 0.0530 - val_mse: 0.0081\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0505 - mse: 0.0072 - val_loss: 0.0529 - val_mse: 0.0081\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0504 - mse: 0.0072 - val_loss: 0.0524 - val_mse: 0.0080\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0504 - mse: 0.0072 - val_loss: 0.0527 - val_mse: 0.0081\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0504 - mse: 0.0072 - val_loss: 0.0526 - val_mse: 0.0080\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0503 - mse: 0.0072 - val_loss: 0.0528 - val_mse: 0.0080\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0503 - mse: 0.0072 - val_loss: 0.0530 - val_mse: 0.0081\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0503 - mse: 0.0072 - val_loss: 0.0527 - val_mse: 0.0080\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0504 - mse: 0.0072 - val_loss: 0.0526 - val_mse: 0.0080\n",
      "Epoch 1/150\n",
      "232/232 [==============================] - 8s 21ms/step - loss: 0.0857 - mse: 0.0163 - val_loss: 0.0599 - val_mse: 0.0107\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0635 - mse: 0.0102 - val_loss: 0.0582 - val_mse: 0.0102\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0605 - mse: 0.0096 - val_loss: 0.0572 - val_mse: 0.0097\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0583 - mse: 0.0090 - val_loss: 0.0564 - val_mse: 0.0093\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0563 - mse: 0.0084 - val_loss: 0.0557 - val_mse: 0.0091\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0550 - mse: 0.0081 - val_loss: 0.0553 - val_mse: 0.0089\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0540 - mse: 0.0080 - val_loss: 0.0554 - val_mse: 0.0090\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0534 - mse: 0.0079 - val_loss: 0.0547 - val_mse: 0.0088\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0529 - mse: 0.0078 - val_loss: 0.0545 - val_mse: 0.0087\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0524 - mse: 0.0076 - val_loss: 0.0545 - val_mse: 0.0087\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0521 - mse: 0.0076 - val_loss: 0.0540 - val_mse: 0.0085\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0516 - mse: 0.0075 - val_loss: 0.0538 - val_mse: 0.0084\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0515 - mse: 0.0074 - val_loss: 0.0538 - val_mse: 0.0084\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0510 - mse: 0.0073 - val_loss: 0.0539 - val_mse: 0.0083\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0509 - mse: 0.0073 - val_loss: 0.0535 - val_mse: 0.0083\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0506 - mse: 0.0072 - val_loss: 0.0527 - val_mse: 0.0080\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0504 - mse: 0.0071 - val_loss: 0.0533 - val_mse: 0.0082\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0501 - mse: 0.0070 - val_loss: 0.0531 - val_mse: 0.0082\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0500 - mse: 0.0070 - val_loss: 0.0525 - val_mse: 0.0079\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0498 - mse: 0.0070 - val_loss: 0.0527 - val_mse: 0.0079\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0497 - mse: 0.0069 - val_loss: 0.0520 - val_mse: 0.0077\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0495 - mse: 0.0069 - val_loss: 0.0520 - val_mse: 0.0078\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0493 - mse: 0.0068 - val_loss: 0.0519 - val_mse: 0.0076\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0493 - mse: 0.0068 - val_loss: 0.0521 - val_mse: 0.0077\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0490 - mse: 0.0067 - val_loss: 0.0516 - val_mse: 0.0075\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0490 - mse: 0.0067 - val_loss: 0.0521 - val_mse: 0.0075\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0487 - mse: 0.0066 - val_loss: 0.0514 - val_mse: 0.0074\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0486 - mse: 0.0066 - val_loss: 0.0523 - val_mse: 0.0077\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0485 - mse: 0.0066 - val_loss: 0.0514 - val_mse: 0.0074\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0483 - mse: 0.0065 - val_loss: 0.0521 - val_mse: 0.0077\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0484 - mse: 0.0065 - val_loss: 0.0523 - val_mse: 0.0077\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0481 - mse: 0.0065 - val_loss: 0.0513 - val_mse: 0.0075\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0480 - mse: 0.0065 - val_loss: 0.0507 - val_mse: 0.0072\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0478 - mse: 0.0064 - val_loss: 0.0508 - val_mse: 0.0073\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0480 - mse: 0.0064 - val_loss: 0.0509 - val_mse: 0.0073\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0476 - mse: 0.0064 - val_loss: 0.0512 - val_mse: 0.0074\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0476 - mse: 0.0064 - val_loss: 0.0507 - val_mse: 0.0072\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0476 - mse: 0.0064 - val_loss: 0.0503 - val_mse: 0.0070\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0475 - mse: 0.0063 - val_loss: 0.0510 - val_mse: 0.0073\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0474 - mse: 0.0063 - val_loss: 0.0505 - val_mse: 0.0071\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0473 - mse: 0.0063 - val_loss: 0.0501 - val_mse: 0.0071\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0473 - mse: 0.0063 - val_loss: 0.0510 - val_mse: 0.0073\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0471 - mse: 0.0062 - val_loss: 0.0497 - val_mse: 0.0070\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0470 - mse: 0.0062 - val_loss: 0.0500 - val_mse: 0.0069\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0469 - mse: 0.0062 - val_loss: 0.0508 - val_mse: 0.0072\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0470 - mse: 0.0062 - val_loss: 0.0498 - val_mse: 0.0070\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0469 - mse: 0.0062 - val_loss: 0.0498 - val_mse: 0.0069\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0468 - mse: 0.0061 - val_loss: 0.0497 - val_mse: 0.0069\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0468 - mse: 0.0062 - val_loss: 0.0494 - val_mse: 0.0069\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0467 - mse: 0.0061 - val_loss: 0.0488 - val_mse: 0.0067\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0466 - mse: 0.0061 - val_loss: 0.0501 - val_mse: 0.0072\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0466 - mse: 0.0061 - val_loss: 0.0489 - val_mse: 0.0067\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0465 - mse: 0.0061 - val_loss: 0.0492 - val_mse: 0.0068\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0465 - mse: 0.0061 - val_loss: 0.0494 - val_mse: 0.0069\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0464 - mse: 0.0061 - val_loss: 0.0489 - val_mse: 0.0067\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0465 - mse: 0.0061 - val_loss: 0.0492 - val_mse: 0.0068\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0462 - mse: 0.0060 - val_loss: 0.0500 - val_mse: 0.0069\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0462 - mse: 0.0060 - val_loss: 0.0488 - val_mse: 0.0068\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0462 - mse: 0.0060 - val_loss: 0.0484 - val_mse: 0.0066\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0461 - mse: 0.0060 - val_loss: 0.0479 - val_mse: 0.0065\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0462 - mse: 0.0060 - val_loss: 0.0487 - val_mse: 0.0066\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0461 - mse: 0.0060 - val_loss: 0.0487 - val_mse: 0.0067\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0461 - mse: 0.0060 - val_loss: 0.0490 - val_mse: 0.0067\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0459 - mse: 0.0060 - val_loss: 0.0488 - val_mse: 0.0066\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0459 - mse: 0.0060 - val_loss: 0.0480 - val_mse: 0.0066\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0459 - mse: 0.0060 - val_loss: 0.0486 - val_mse: 0.0067\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0458 - mse: 0.0059 - val_loss: 0.0483 - val_mse: 0.0066\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0458 - mse: 0.0059 - val_loss: 0.0476 - val_mse: 0.0063\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0457 - mse: 0.0059 - val_loss: 0.0483 - val_mse: 0.0065\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0457 - mse: 0.0059 - val_loss: 0.0478 - val_mse: 0.0064\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0457 - mse: 0.0059 - val_loss: 0.0475 - val_mse: 0.0064\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0458 - mse: 0.0059 - val_loss: 0.0476 - val_mse: 0.0064\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0457 - mse: 0.0059 - val_loss: 0.0473 - val_mse: 0.0063\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0455 - mse: 0.0059 - val_loss: 0.0475 - val_mse: 0.0064\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0456 - mse: 0.0059 - val_loss: 0.0475 - val_mse: 0.0064\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0455 - mse: 0.0059 - val_loss: 0.0472 - val_mse: 0.0063\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0456 - mse: 0.0059 - val_loss: 0.0471 - val_mse: 0.0062\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0454 - mse: 0.0059 - val_loss: 0.0469 - val_mse: 0.0062\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0455 - mse: 0.0059 - val_loss: 0.0471 - val_mse: 0.0062\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0456 - mse: 0.0059 - val_loss: 0.0482 - val_mse: 0.0065\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0455 - mse: 0.0059 - val_loss: 0.0466 - val_mse: 0.0061\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0453 - mse: 0.0059 - val_loss: 0.0472 - val_mse: 0.0063\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0452 - mse: 0.0058 - val_loss: 0.0480 - val_mse: 0.0065\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0453 - mse: 0.0059 - val_loss: 0.0469 - val_mse: 0.0062\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0452 - mse: 0.0058 - val_loss: 0.0473 - val_mse: 0.0063\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0453 - mse: 0.0059 - val_loss: 0.0475 - val_mse: 0.0064\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0452 - mse: 0.0058 - val_loss: 0.0466 - val_mse: 0.0061\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0452 - mse: 0.0058 - val_loss: 0.0475 - val_mse: 0.0063\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0452 - mse: 0.0058 - val_loss: 0.0476 - val_mse: 0.0063\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0452 - mse: 0.0058 - val_loss: 0.0468 - val_mse: 0.0063\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0451 - mse: 0.0058 - val_loss: 0.0471 - val_mse: 0.0063\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0450 - mse: 0.0058 - val_loss: 0.0468 - val_mse: 0.0062\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0450 - mse: 0.0058 - val_loss: 0.0462 - val_mse: 0.0060\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0450 - mse: 0.0058 - val_loss: 0.0463 - val_mse: 0.0060\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0450 - mse: 0.0058 - val_loss: 0.0463 - val_mse: 0.0061\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0450 - mse: 0.0058 - val_loss: 0.0470 - val_mse: 0.0062\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0450 - mse: 0.0058 - val_loss: 0.0469 - val_mse: 0.0062\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0449 - mse: 0.0058 - val_loss: 0.0461 - val_mse: 0.0060\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0449 - mse: 0.0058 - val_loss: 0.0478 - val_mse: 0.0063\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0450 - mse: 0.0058 - val_loss: 0.0462 - val_mse: 0.0060\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0448 - mse: 0.0057 - val_loss: 0.0469 - val_mse: 0.0062\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0449 - mse: 0.0057 - val_loss: 0.0472 - val_mse: 0.0063\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0448 - mse: 0.0057 - val_loss: 0.0465 - val_mse: 0.0062\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0448 - mse: 0.0057 - val_loss: 0.0464 - val_mse: 0.0061\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0448 - mse: 0.0057 - val_loss: 0.0473 - val_mse: 0.0063\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0449 - mse: 0.0057 - val_loss: 0.0460 - val_mse: 0.0060\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0448 - mse: 0.0057 - val_loss: 0.0464 - val_mse: 0.0061\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0448 - mse: 0.0057 - val_loss: 0.0472 - val_mse: 0.0063\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0447 - mse: 0.0057 - val_loss: 0.0480 - val_mse: 0.0066\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0447 - mse: 0.0057 - val_loss: 0.0463 - val_mse: 0.0060\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0446 - mse: 0.0057 - val_loss: 0.0465 - val_mse: 0.0061\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0446 - mse: 0.0057 - val_loss: 0.0464 - val_mse: 0.0061\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0448 - mse: 0.0057 - val_loss: 0.0460 - val_mse: 0.0059\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0446 - mse: 0.0057 - val_loss: 0.0456 - val_mse: 0.0059\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0445 - mse: 0.0057 - val_loss: 0.0468 - val_mse: 0.0062\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0446 - mse: 0.0057 - val_loss: 0.0469 - val_mse: 0.0063\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0447 - mse: 0.0057 - val_loss: 0.0464 - val_mse: 0.0060\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0445 - mse: 0.0056 - val_loss: 0.0461 - val_mse: 0.0060\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0445 - mse: 0.0056 - val_loss: 0.0464 - val_mse: 0.0061\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0445 - mse: 0.0056 - val_loss: 0.0471 - val_mse: 0.0062\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0444 - mse: 0.0056 - val_loss: 0.0471 - val_mse: 0.0063\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0444 - mse: 0.0056 - val_loss: 0.0458 - val_mse: 0.0059\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0443 - mse: 0.0056 - val_loss: 0.0467 - val_mse: 0.0061\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0444 - mse: 0.0056 - val_loss: 0.0467 - val_mse: 0.0062\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0444 - mse: 0.0056 - val_loss: 0.0463 - val_mse: 0.0058\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0444 - mse: 0.0056 - val_loss: 0.0464 - val_mse: 0.0060\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0443 - mse: 0.0056 - val_loss: 0.0467 - val_mse: 0.0061\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0444 - mse: 0.0056 - val_loss: 0.0467 - val_mse: 0.0061\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0055 - val_loss: 0.0467 - val_mse: 0.0060\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0055 - val_loss: 0.0475 - val_mse: 0.0064\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0055 - val_loss: 0.0453 - val_mse: 0.0056\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0055 - val_loss: 0.0467 - val_mse: 0.0062\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0055 - val_loss: 0.0464 - val_mse: 0.0061\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0055 - val_loss: 0.0459 - val_mse: 0.0059\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0055 - val_loss: 0.0462 - val_mse: 0.0060\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0055 - val_loss: 0.0467 - val_mse: 0.0060\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0441 - mse: 0.0055 - val_loss: 0.0457 - val_mse: 0.0059\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0055 - val_loss: 0.0462 - val_mse: 0.0059\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0055 - val_loss: 0.0465 - val_mse: 0.0061\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0055 - val_loss: 0.0466 - val_mse: 0.0061\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0439 - mse: 0.0054 - val_loss: 0.0461 - val_mse: 0.0060\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0439 - mse: 0.0054 - val_loss: 0.0458 - val_mse: 0.0059\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0440 - mse: 0.0055 - val_loss: 0.0461 - val_mse: 0.0059\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0439 - mse: 0.0054 - val_loss: 0.0459 - val_mse: 0.0059\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0440 - mse: 0.0055 - val_loss: 0.0456 - val_mse: 0.0058\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0440 - mse: 0.0055 - val_loss: 0.0452 - val_mse: 0.0057\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0439 - mse: 0.0054 - val_loss: 0.0457 - val_mse: 0.0058\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0439 - mse: 0.0055 - val_loss: 0.0456 - val_mse: 0.0059\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0439 - mse: 0.0054 - val_loss: 0.0459 - val_mse: 0.0059\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0438 - mse: 0.0054 - val_loss: 0.0456 - val_mse: 0.0058\n",
      "Epoch 1/150\n",
      "232/232 [==============================] - 9s 23ms/step - loss: 0.0640 - mse: 0.0104 - val_loss: 0.0568 - val_mse: 0.0096\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0534 - mse: 0.0080 - val_loss: 0.0542 - val_mse: 0.0085\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0519 - mse: 0.0077 - val_loss: 0.0538 - val_mse: 0.0086\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0511 - mse: 0.0075 - val_loss: 0.0537 - val_mse: 0.0085\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0502 - mse: 0.0073 - val_loss: 0.0532 - val_mse: 0.0083\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0498 - mse: 0.0072 - val_loss: 0.0521 - val_mse: 0.0080\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0493 - mse: 0.0071 - val_loss: 0.0533 - val_mse: 0.0082\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0490 - mse: 0.0070 - val_loss: 0.0520 - val_mse: 0.0080\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0485 - mse: 0.0069 - val_loss: 0.0512 - val_mse: 0.0076\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0483 - mse: 0.0068 - val_loss: 0.0527 - val_mse: 0.0080\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0480 - mse: 0.0067 - val_loss: 0.0500 - val_mse: 0.0069\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0476 - mse: 0.0065 - val_loss: 0.0486 - val_mse: 0.0068\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0475 - mse: 0.0065 - val_loss: 0.0508 - val_mse: 0.0073\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0479 - mse: 0.0067 - val_loss: 0.0506 - val_mse: 0.0073\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0472 - mse: 0.0064 - val_loss: 0.0496 - val_mse: 0.0071\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0471 - mse: 0.0064 - val_loss: 0.0532 - val_mse: 0.0077\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0467 - mse: 0.0062 - val_loss: 0.0473 - val_mse: 0.0064\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0471 - mse: 0.0064 - val_loss: 0.0476 - val_mse: 0.0065\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0459 - mse: 0.0060 - val_loss: 0.0472 - val_mse: 0.0062\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0458 - mse: 0.0060 - val_loss: 0.0497 - val_mse: 0.0069\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0454 - mse: 0.0059 - val_loss: 0.0490 - val_mse: 0.0068\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0455 - mse: 0.0059 - val_loss: 0.0477 - val_mse: 0.0064\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0451 - mse: 0.0058 - val_loss: 0.0490 - val_mse: 0.0067\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0454 - mse: 0.0059 - val_loss: 0.0465 - val_mse: 0.0060\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0450 - mse: 0.0058 - val_loss: 0.0470 - val_mse: 0.0061\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0449 - mse: 0.0058 - val_loss: 0.0476 - val_mse: 0.0065\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0448 - mse: 0.0057 - val_loss: 0.0468 - val_mse: 0.0061\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0447 - mse: 0.0057 - val_loss: 0.0462 - val_mse: 0.0061\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0446 - mse: 0.0057 - val_loss: 0.0460 - val_mse: 0.0059\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0445 - mse: 0.0057 - val_loss: 0.0467 - val_mse: 0.0061\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0447 - mse: 0.0057 - val_loss: 0.0473 - val_mse: 0.0063\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0445 - mse: 0.0056 - val_loss: 0.0456 - val_mse: 0.0059\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0443 - mse: 0.0056 - val_loss: 0.0461 - val_mse: 0.0061\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0443 - mse: 0.0056 - val_loss: 0.0456 - val_mse: 0.0058\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0443 - mse: 0.0056 - val_loss: 0.0458 - val_mse: 0.0059\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0056 - val_loss: 0.0465 - val_mse: 0.0061\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0056 - val_loss: 0.0469 - val_mse: 0.0061\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0056 - val_loss: 0.0456 - val_mse: 0.0058\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0056 - val_loss: 0.0456 - val_mse: 0.0059\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0056 - val_loss: 0.0473 - val_mse: 0.0064\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0056 - val_loss: 0.0462 - val_mse: 0.0061\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0056 - val_loss: 0.0467 - val_mse: 0.0060\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0440 - mse: 0.0055 - val_loss: 0.0452 - val_mse: 0.0058\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0440 - mse: 0.0055 - val_loss: 0.0458 - val_mse: 0.0059\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0056 - val_loss: 0.0466 - val_mse: 0.0061\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0439 - mse: 0.0055 - val_loss: 0.0454 - val_mse: 0.0059\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0439 - mse: 0.0055 - val_loss: 0.0470 - val_mse: 0.0061\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0439 - mse: 0.0055 - val_loss: 0.0464 - val_mse: 0.0062\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0438 - mse: 0.0055 - val_loss: 0.0454 - val_mse: 0.0058\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0438 - mse: 0.0055 - val_loss: 0.0457 - val_mse: 0.0059\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0437 - mse: 0.0054 - val_loss: 0.0469 - val_mse: 0.0062\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0055 - val_loss: 0.0461 - val_mse: 0.0059\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0437 - mse: 0.0054 - val_loss: 0.0466 - val_mse: 0.0060\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0435 - mse: 0.0054 - val_loss: 0.0467 - val_mse: 0.0061\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0435 - mse: 0.0054 - val_loss: 0.0466 - val_mse: 0.0062\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0434 - mse: 0.0053 - val_loss: 0.0461 - val_mse: 0.0061\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0435 - mse: 0.0054 - val_loss: 0.0474 - val_mse: 0.0063\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0437 - mse: 0.0054 - val_loss: 0.0460 - val_mse: 0.0060\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0434 - mse: 0.0053 - val_loss: 0.0455 - val_mse: 0.0059\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0433 - mse: 0.0053 - val_loss: 0.0460 - val_mse: 0.0061\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0431 - mse: 0.0052 - val_loss: 0.0463 - val_mse: 0.0061\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0434 - mse: 0.0053 - val_loss: 0.0460 - val_mse: 0.0061\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0432 - mse: 0.0053 - val_loss: 0.0456 - val_mse: 0.0059\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0429 - mse: 0.0052 - val_loss: 0.0476 - val_mse: 0.0064\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0433 - mse: 0.0053 - val_loss: 0.0454 - val_mse: 0.0058\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0430 - mse: 0.0052 - val_loss: 0.0462 - val_mse: 0.0060\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0428 - mse: 0.0051 - val_loss: 0.0470 - val_mse: 0.0063\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0429 - mse: 0.0052 - val_loss: 0.0455 - val_mse: 0.0059\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0427 - mse: 0.0051 - val_loss: 0.0456 - val_mse: 0.0059\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0432 - mse: 0.0053 - val_loss: 0.0460 - val_mse: 0.0060\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0427 - mse: 0.0051 - val_loss: 0.0465 - val_mse: 0.0062\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0427 - mse: 0.0051 - val_loss: 0.0466 - val_mse: 0.0061\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0426 - mse: 0.0051 - val_loss: 0.0474 - val_mse: 0.0063\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0430 - mse: 0.0052 - val_loss: 0.0459 - val_mse: 0.0060\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0430 - mse: 0.0052 - val_loss: 0.0479 - val_mse: 0.0064\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0427 - mse: 0.0052 - val_loss: 0.0458 - val_mse: 0.0060\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0427 - mse: 0.0051 - val_loss: 0.0457 - val_mse: 0.0059\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0426 - mse: 0.0051 - val_loss: 0.0453 - val_mse: 0.0058\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0426 - mse: 0.0051 - val_loss: 0.0464 - val_mse: 0.0061\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0425 - mse: 0.0051 - val_loss: 0.0451 - val_mse: 0.0059\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0425 - mse: 0.0051 - val_loss: 0.0455 - val_mse: 0.0059\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0423 - mse: 0.0050 - val_loss: 0.0464 - val_mse: 0.0061\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0424 - mse: 0.0051 - val_loss: 0.0462 - val_mse: 0.0060\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0422 - mse: 0.0050 - val_loss: 0.0460 - val_mse: 0.0060\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0424 - mse: 0.0050 - val_loss: 0.0454 - val_mse: 0.0059\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0423 - mse: 0.0050 - val_loss: 0.0456 - val_mse: 0.0059\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0424 - mse: 0.0050 - val_loss: 0.0453 - val_mse: 0.0059\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0425 - mse: 0.0051 - val_loss: 0.0459 - val_mse: 0.0060\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0425 - mse: 0.0051 - val_loss: 0.0458 - val_mse: 0.0060\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0423 - mse: 0.0050 - val_loss: 0.0461 - val_mse: 0.0060\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0421 - mse: 0.0050 - val_loss: 0.0458 - val_mse: 0.0060\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0421 - mse: 0.0049 - val_loss: 0.0456 - val_mse: 0.0059\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0423 - mse: 0.0050 - val_loss: 0.0455 - val_mse: 0.0059\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0421 - mse: 0.0050 - val_loss: 0.0461 - val_mse: 0.0061\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0422 - mse: 0.0050 - val_loss: 0.0456 - val_mse: 0.0060\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0420 - mse: 0.0049 - val_loss: 0.0450 - val_mse: 0.0058\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0422 - mse: 0.0050 - val_loss: 0.0456 - val_mse: 0.0060\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0419 - mse: 0.0049 - val_loss: 0.0460 - val_mse: 0.0060\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0420 - mse: 0.0049 - val_loss: 0.0456 - val_mse: 0.0059\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0420 - mse: 0.0049 - val_loss: 0.0458 - val_mse: 0.0060\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0419 - mse: 0.0049 - val_loss: 0.0453 - val_mse: 0.0059\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0424 - mse: 0.0051 - val_loss: 0.0454 - val_mse: 0.0059\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0419 - mse: 0.0049 - val_loss: 0.0459 - val_mse: 0.0061\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0419 - mse: 0.0049 - val_loss: 0.0458 - val_mse: 0.0060\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0418 - mse: 0.0049 - val_loss: 0.0452 - val_mse: 0.0058\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0419 - mse: 0.0049 - val_loss: 0.0461 - val_mse: 0.0060\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0423 - mse: 0.0051 - val_loss: 0.0457 - val_mse: 0.0060\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0418 - mse: 0.0049 - val_loss: 0.0457 - val_mse: 0.0060\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0417 - mse: 0.0048 - val_loss: 0.0453 - val_mse: 0.0059\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0417 - mse: 0.0048 - val_loss: 0.0451 - val_mse: 0.0057\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0417 - mse: 0.0048 - val_loss: 0.0467 - val_mse: 0.0062\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0417 - mse: 0.0048 - val_loss: 0.0454 - val_mse: 0.0059\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0416 - mse: 0.0048 - val_loss: 0.0451 - val_mse: 0.0059\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0416 - mse: 0.0048 - val_loss: 0.0452 - val_mse: 0.0058\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0416 - mse: 0.0048 - val_loss: 0.0460 - val_mse: 0.0060\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0415 - mse: 0.0048 - val_loss: 0.0454 - val_mse: 0.0059\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0416 - mse: 0.0048 - val_loss: 0.0454 - val_mse: 0.0059\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0048 - val_loss: 0.0459 - val_mse: 0.0060\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0415 - mse: 0.0048 - val_loss: 0.0454 - val_mse: 0.0059\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0415 - mse: 0.0048 - val_loss: 0.0450 - val_mse: 0.0058\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0048 - val_loss: 0.0460 - val_mse: 0.0060\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0048 - val_loss: 0.0452 - val_mse: 0.0059\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0048 - val_loss: 0.0460 - val_mse: 0.0061\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0415 - mse: 0.0048 - val_loss: 0.0461 - val_mse: 0.0061\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0412 - mse: 0.0047 - val_loss: 0.0461 - val_mse: 0.0061\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0412 - mse: 0.0047 - val_loss: 0.0459 - val_mse: 0.0060\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0412 - mse: 0.0047 - val_loss: 0.0457 - val_mse: 0.0060\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0414 - mse: 0.0048 - val_loss: 0.0451 - val_mse: 0.0059\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0411 - mse: 0.0047 - val_loss: 0.0460 - val_mse: 0.0061\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0048 - val_loss: 0.0458 - val_mse: 0.0060\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0411 - mse: 0.0047 - val_loss: 0.0461 - val_mse: 0.0061\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0414 - mse: 0.0048 - val_loss: 0.0461 - val_mse: 0.0061\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0412 - mse: 0.0047 - val_loss: 0.0452 - val_mse: 0.0059\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0048 - val_loss: 0.0454 - val_mse: 0.0059\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0409 - mse: 0.0047 - val_loss: 0.0463 - val_mse: 0.0061\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0047 - val_loss: 0.0457 - val_mse: 0.0059\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0409 - mse: 0.0047 - val_loss: 0.0457 - val_mse: 0.0060\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0411 - mse: 0.0047 - val_loss: 0.0452 - val_mse: 0.0059\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0408 - mse: 0.0046 - val_loss: 0.0454 - val_mse: 0.0059\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0416 - mse: 0.0049 - val_loss: 0.0453 - val_mse: 0.0059\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0412 - mse: 0.0048 - val_loss: 0.0457 - val_mse: 0.0059\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0047 - val_loss: 0.0473 - val_mse: 0.0064\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0409 - mse: 0.0047 - val_loss: 0.0460 - val_mse: 0.0061\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0046 - val_loss: 0.0468 - val_mse: 0.0062\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0409 - mse: 0.0047 - val_loss: 0.0455 - val_mse: 0.0059\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0408 - mse: 0.0046 - val_loss: 0.0460 - val_mse: 0.0061\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0046 - val_loss: 0.0464 - val_mse: 0.0062\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0047 - val_loss: 0.0460 - val_mse: 0.0061\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0407 - mse: 0.0046 - val_loss: 0.0452 - val_mse: 0.0059\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0407 - mse: 0.0046 - val_loss: 0.0456 - val_mse: 0.0060\n",
      "Epoch 1/150\n",
      "232/232 [==============================] - 8s 23ms/step - loss: 0.0590 - mse: 0.0098 - val_loss: 0.0538 - val_mse: 0.0084\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0506 - mse: 0.0074 - val_loss: 0.0525 - val_mse: 0.0079\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0496 - mse: 0.0071 - val_loss: 0.0507 - val_mse: 0.0074\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0491 - mse: 0.0069 - val_loss: 0.0502 - val_mse: 0.0072\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0486 - mse: 0.0068 - val_loss: 0.0524 - val_mse: 0.0073\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0488 - mse: 0.0069 - val_loss: 0.0535 - val_mse: 0.0080\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0482 - mse: 0.0067 - val_loss: 0.0505 - val_mse: 0.0071\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0482 - mse: 0.0067 - val_loss: 0.0489 - val_mse: 0.0071\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0482 - mse: 0.0068 - val_loss: 0.0472 - val_mse: 0.0066\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0477 - mse: 0.0066 - val_loss: 0.0479 - val_mse: 0.0068\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0476 - mse: 0.0065 - val_loss: 0.0509 - val_mse: 0.0074\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0474 - mse: 0.0065 - val_loss: 0.0488 - val_mse: 0.0070\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0475 - mse: 0.0065 - val_loss: 0.0492 - val_mse: 0.0071\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0476 - mse: 0.0065 - val_loss: 0.0486 - val_mse: 0.0065\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0475 - mse: 0.0066 - val_loss: 0.0476 - val_mse: 0.0067\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0469 - mse: 0.0064 - val_loss: 0.0470 - val_mse: 0.0062\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0471 - mse: 0.0064 - val_loss: 0.0483 - val_mse: 0.0066\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0466 - mse: 0.0062 - val_loss: 0.0465 - val_mse: 0.0061\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0466 - mse: 0.0063 - val_loss: 0.0469 - val_mse: 0.0063\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0462 - mse: 0.0061 - val_loss: 0.0466 - val_mse: 0.0061\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0463 - mse: 0.0062 - val_loss: 0.0485 - val_mse: 0.0069\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0459 - mse: 0.0061 - val_loss: 0.0469 - val_mse: 0.0061\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0464 - mse: 0.0062 - val_loss: 0.0465 - val_mse: 0.0065\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0461 - mse: 0.0061 - val_loss: 0.0461 - val_mse: 0.0063\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0458 - mse: 0.0060 - val_loss: 0.0465 - val_mse: 0.0061\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0458 - mse: 0.0060 - val_loss: 0.0465 - val_mse: 0.0061\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0456 - mse: 0.0060 - val_loss: 0.0490 - val_mse: 0.0065\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0458 - mse: 0.0060 - val_loss: 0.0473 - val_mse: 0.0063\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0455 - mse: 0.0059 - val_loss: 0.0469 - val_mse: 0.0063\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0453 - mse: 0.0059 - val_loss: 0.0450 - val_mse: 0.0057\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0453 - mse: 0.0059 - val_loss: 0.0483 - val_mse: 0.0068\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0461 - mse: 0.0061 - val_loss: 0.0481 - val_mse: 0.0067\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0457 - mse: 0.0060 - val_loss: 0.0476 - val_mse: 0.0065\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0451 - mse: 0.0058 - val_loss: 0.0463 - val_mse: 0.0059\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0456 - mse: 0.0060 - val_loss: 0.0462 - val_mse: 0.0061\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0460 - mse: 0.0061 - val_loss: 0.0475 - val_mse: 0.0067\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0455 - mse: 0.0059 - val_loss: 0.0460 - val_mse: 0.0061\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0450 - mse: 0.0058 - val_loss: 0.0466 - val_mse: 0.0061\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0449 - mse: 0.0058 - val_loss: 0.0470 - val_mse: 0.0062\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0450 - mse: 0.0058 - val_loss: 0.0471 - val_mse: 0.0061\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0448 - mse: 0.0057 - val_loss: 0.0456 - val_mse: 0.0058\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0448 - mse: 0.0057 - val_loss: 0.0452 - val_mse: 0.0057\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0444 - mse: 0.0056 - val_loss: 0.0451 - val_mse: 0.0059\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0446 - mse: 0.0057 - val_loss: 0.0461 - val_mse: 0.0059\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0450 - mse: 0.0058 - val_loss: 0.0451 - val_mse: 0.0059\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0447 - mse: 0.0057 - val_loss: 0.0473 - val_mse: 0.0061\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0447 - mse: 0.0057 - val_loss: 0.0472 - val_mse: 0.0063\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0439 - mse: 0.0054 - val_loss: 0.0479 - val_mse: 0.0070\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0055 - val_loss: 0.0498 - val_mse: 0.0064\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0441 - mse: 0.0055 - val_loss: 0.0476 - val_mse: 0.0065\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0056 - val_loss: 0.0457 - val_mse: 0.0059\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0443 - mse: 0.0056 - val_loss: 0.0469 - val_mse: 0.0065\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0055 - val_loss: 0.0462 - val_mse: 0.0060\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0441 - mse: 0.0055 - val_loss: 0.0455 - val_mse: 0.0058\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0438 - mse: 0.0054 - val_loss: 0.0446 - val_mse: 0.0057\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0431 - mse: 0.0052 - val_loss: 0.0447 - val_mse: 0.0057\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0436 - mse: 0.0053 - val_loss: 0.0458 - val_mse: 0.0061\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0445 - mse: 0.0056 - val_loss: 0.0451 - val_mse: 0.0059\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0436 - mse: 0.0054 - val_loss: 0.0442 - val_mse: 0.0056\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0433 - mse: 0.0053 - val_loss: 0.0454 - val_mse: 0.0059\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0432 - mse: 0.0053 - val_loss: 0.0436 - val_mse: 0.0056\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0431 - mse: 0.0052 - val_loss: 0.0445 - val_mse: 0.0056\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0430 - mse: 0.0052 - val_loss: 0.0477 - val_mse: 0.0065\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0431 - mse: 0.0052 - val_loss: 0.0468 - val_mse: 0.0059\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0433 - mse: 0.0053 - val_loss: 0.0456 - val_mse: 0.0059\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0432 - mse: 0.0053 - val_loss: 0.0465 - val_mse: 0.0060\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0429 - mse: 0.0052 - val_loss: 0.0478 - val_mse: 0.0068\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0427 - mse: 0.0051 - val_loss: 0.0426 - val_mse: 0.0053\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0426 - mse: 0.0051 - val_loss: 0.0454 - val_mse: 0.0059\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0423 - mse: 0.0050 - val_loss: 0.0452 - val_mse: 0.0057\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0430 - mse: 0.0053 - val_loss: 0.0443 - val_mse: 0.0057\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0422 - mse: 0.0050 - val_loss: 0.0427 - val_mse: 0.0053\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0419 - mse: 0.0049 - val_loss: 0.0462 - val_mse: 0.0061\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0425 - mse: 0.0051 - val_loss: 0.0418 - val_mse: 0.0051\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0425 - mse: 0.0051 - val_loss: 0.0412 - val_mse: 0.0051\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0416 - mse: 0.0049 - val_loss: 0.0405 - val_mse: 0.0049\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0416 - mse: 0.0049 - val_loss: 0.0420 - val_mse: 0.0051\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0411 - mse: 0.0047 - val_loss: 0.0412 - val_mse: 0.0050\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0411 - mse: 0.0047 - val_loss: 0.0404 - val_mse: 0.0049\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0047 - val_loss: 0.0413 - val_mse: 0.0051\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0048 - val_loss: 0.0393 - val_mse: 0.0046\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0415 - mse: 0.0048 - val_loss: 0.0428 - val_mse: 0.0056\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0048 - val_loss: 0.0403 - val_mse: 0.0048\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0408 - mse: 0.0047 - val_loss: 0.0398 - val_mse: 0.0047\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0415 - mse: 0.0049 - val_loss: 0.0411 - val_mse: 0.0051\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0409 - mse: 0.0047 - val_loss: 0.0407 - val_mse: 0.0050\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0414 - mse: 0.0048 - val_loss: 0.0395 - val_mse: 0.0046\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0416 - mse: 0.0048 - val_loss: 0.0424 - val_mse: 0.0050\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0409 - mse: 0.0047 - val_loss: 0.0403 - val_mse: 0.0048\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0047 - val_loss: 0.0404 - val_mse: 0.0048\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0046 - val_loss: 0.0399 - val_mse: 0.0047\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0412 - mse: 0.0048 - val_loss: 0.0435 - val_mse: 0.0057\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0404 - mse: 0.0046 - val_loss: 0.0405 - val_mse: 0.0048\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0403 - mse: 0.0045 - val_loss: 0.0437 - val_mse: 0.0055\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0404 - mse: 0.0046 - val_loss: 0.0402 - val_mse: 0.0048\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0046 - val_loss: 0.0409 - val_mse: 0.0049\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0405 - mse: 0.0046 - val_loss: 0.0408 - val_mse: 0.0049\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0407 - mse: 0.0046 - val_loss: 0.0427 - val_mse: 0.0055\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0408 - mse: 0.0047 - val_loss: 0.0419 - val_mse: 0.0052\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0402 - mse: 0.0045 - val_loss: 0.0402 - val_mse: 0.0049\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0407 - mse: 0.0046 - val_loss: 0.0421 - val_mse: 0.0052\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0409 - mse: 0.0047 - val_loss: 0.0417 - val_mse: 0.0052\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0401 - mse: 0.0045 - val_loss: 0.0405 - val_mse: 0.0048\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0403 - mse: 0.0045 - val_loss: 0.0396 - val_mse: 0.0048\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0399 - mse: 0.0044 - val_loss: 0.0450 - val_mse: 0.0058\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0402 - mse: 0.0045 - val_loss: 0.0400 - val_mse: 0.0047\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0047 - val_loss: 0.0436 - val_mse: 0.0060\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0424 - mse: 0.0051 - val_loss: 0.0415 - val_mse: 0.0054\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0407 - mse: 0.0046 - val_loss: 0.0394 - val_mse: 0.0047\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0408 - mse: 0.0047 - val_loss: 0.0397 - val_mse: 0.0047\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0401 - mse: 0.0045 - val_loss: 0.0430 - val_mse: 0.0057\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0407 - mse: 0.0046 - val_loss: 0.0398 - val_mse: 0.0046\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0404 - mse: 0.0045 - val_loss: 0.0408 - val_mse: 0.0049\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0401 - mse: 0.0045 - val_loss: 0.0411 - val_mse: 0.0048\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0401 - mse: 0.0045 - val_loss: 0.0439 - val_mse: 0.0057\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0402 - mse: 0.0045 - val_loss: 0.0407 - val_mse: 0.0049\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0399 - mse: 0.0044 - val_loss: 0.0395 - val_mse: 0.0046\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0403 - mse: 0.0045 - val_loss: 0.0412 - val_mse: 0.0050\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0408 - mse: 0.0047 - val_loss: 0.0385 - val_mse: 0.0044\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0398 - mse: 0.0044 - val_loss: 0.0395 - val_mse: 0.0047\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0396 - mse: 0.0044 - val_loss: 0.0412 - val_mse: 0.0048\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0399 - mse: 0.0044 - val_loss: 0.0411 - val_mse: 0.0048\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0396 - mse: 0.0043 - val_loss: 0.0398 - val_mse: 0.0047\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0401 - mse: 0.0045 - val_loss: 0.0395 - val_mse: 0.0046\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0394 - mse: 0.0043 - val_loss: 0.0410 - val_mse: 0.0048\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0397 - mse: 0.0043 - val_loss: 0.0389 - val_mse: 0.0045\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0397 - mse: 0.0044 - val_loss: 0.0395 - val_mse: 0.0046\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0396 - mse: 0.0044 - val_loss: 0.0389 - val_mse: 0.0046\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0397 - mse: 0.0043 - val_loss: 0.0402 - val_mse: 0.0049\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0395 - mse: 0.0043 - val_loss: 0.0435 - val_mse: 0.0057\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0394 - mse: 0.0043 - val_loss: 0.0393 - val_mse: 0.0047\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0393 - mse: 0.0043 - val_loss: 0.0392 - val_mse: 0.0046\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0395 - mse: 0.0043 - val_loss: 0.0388 - val_mse: 0.0046\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0399 - mse: 0.0044 - val_loss: 0.0464 - val_mse: 0.0063\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0395 - mse: 0.0043 - val_loss: 0.0399 - val_mse: 0.0046\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0398 - mse: 0.0044 - val_loss: 0.0388 - val_mse: 0.0046\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0393 - mse: 0.0043 - val_loss: 0.0409 - val_mse: 0.0050\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0396 - mse: 0.0043 - val_loss: 0.0417 - val_mse: 0.0051\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0390 - mse: 0.0042 - val_loss: 0.0391 - val_mse: 0.0046\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0395 - mse: 0.0043 - val_loss: 0.0391 - val_mse: 0.0046\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0391 - mse: 0.0042 - val_loss: 0.0417 - val_mse: 0.0052\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0396 - mse: 0.0043 - val_loss: 0.0402 - val_mse: 0.0048\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0400 - mse: 0.0045 - val_loss: 0.0417 - val_mse: 0.0055\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0400 - mse: 0.0044 - val_loss: 0.0400 - val_mse: 0.0047\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0393 - mse: 0.0043 - val_loss: 0.0407 - val_mse: 0.0051\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0395 - mse: 0.0043 - val_loss: 0.0400 - val_mse: 0.0048\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0393 - mse: 0.0043 - val_loss: 0.0410 - val_mse: 0.0051\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0389 - mse: 0.0042 - val_loss: 0.0441 - val_mse: 0.0059\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0395 - mse: 0.0043 - val_loss: 0.0415 - val_mse: 0.0052\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0394 - mse: 0.0043 - val_loss: 0.0426 - val_mse: 0.0054\n",
      "Epoch 1/150\n",
      "232/232 [==============================] - 9s 23ms/step - loss: 0.3623 - mse: 0.1632 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 5s 20ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 4s 19ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 4s 19ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 4s 19ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 4s 19ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 4s 19ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 4s 19ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 4s 19ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.3630 - mse: 0.1636 - val_loss: 0.3476 - val_mse: 0.1515\n",
      "[0.05256679281592369, 0.04557053744792938, 0.04561924934387207, 0.042589813470840454, 0.3475542366504669]\n"
     ]
    }
   ],
   "source": [
    "learning_rates=[.00001,.0001,.001,.01,.1] #setting hyperparameter values to be considered\n",
    "losses = [] # empty array to hold validation losses for each condition\n",
    "for lr in learning_rates:\n",
    "  gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=corrmatrix,\n",
    "    gc_layer_sizes=[16, 10],\n",
    "    gc_activations=[\"relu\", \"relu\"],\n",
    "    lstm_layer_sizes=[200, 200],\n",
    "    lstm_activations=[\"tanh\", \"tanh\"],\n",
    "    ) # model needs to be redefined each loop. compiling the model without redefinition saves model weights between each hyperparameter value\n",
    "  x_input, x_output = gcn_lstm.in_out_tensors()\n",
    "\n",
    "  model = Model(inputs=x_input, outputs=x_output)\n",
    "  optimizer2=keras.optimizers.Adam(learning_rate=lr)\n",
    "  model.compile(optimizer=optimizer2, loss=\"mae\", metrics=[\"mse\"])\n",
    "  history = model.fit(\n",
    "      trainX,\n",
    "      trainY,\n",
    "      epochs=150,#150 epochs is sufficient to allow low learning rate models to reach local minimums\n",
    "      batch_size=200,\n",
    "      shuffle=True,\n",
    "      verbose=1,\n",
    "      validation_data=(valX, valY),\n",
    "  )# fitting training data to the model and optimising performance based on validation set\n",
    "  losses.append(history.history['val_loss'][149])\n",
    "\n",
    "print(losses)\n",
    "\n",
    "with open(\"model_performances/tuning_losses.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(str(item) for item in losses))#writing validation loss performance to a text file for later consideration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9bc637a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MU7sH4YwQMmQ",
    "outputId": "cd5cef2a-639b-46c5-bceb-9cdf3c232c97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "232/232 [==============================] - 13s 21ms/step - loss: 0.0621 - mse: 0.0108 - val_loss: 0.0552 - val_mse: 0.0091\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0517 - mse: 0.0079 - val_loss: 0.0535 - val_mse: 0.0085\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0503 - mse: 0.0074 - val_loss: 0.0535 - val_mse: 0.0084\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0497 - mse: 0.0072 - val_loss: 0.0517 - val_mse: 0.0078\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0494 - mse: 0.0071 - val_loss: 0.0548 - val_mse: 0.0082\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0491 - mse: 0.0070 - val_loss: 0.0522 - val_mse: 0.0079\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0488 - mse: 0.0069 - val_loss: 0.0529 - val_mse: 0.0079\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0487 - mse: 0.0069 - val_loss: 0.0533 - val_mse: 0.0083\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0484 - mse: 0.0068 - val_loss: 0.0521 - val_mse: 0.0079\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0482 - mse: 0.0068 - val_loss: 0.0511 - val_mse: 0.0075\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0479 - mse: 0.0067 - val_loss: 0.0503 - val_mse: 0.0073\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0478 - mse: 0.0066 - val_loss: 0.0500 - val_mse: 0.0072\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0478 - mse: 0.0066 - val_loss: 0.0483 - val_mse: 0.0068\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0479 - mse: 0.0067 - val_loss: 0.0506 - val_mse: 0.0074\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0476 - mse: 0.0066 - val_loss: 0.0489 - val_mse: 0.0069\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0473 - mse: 0.0065 - val_loss: 0.0514 - val_mse: 0.0073\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0470 - mse: 0.0064 - val_loss: 0.0492 - val_mse: 0.0068\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0472 - mse: 0.0064 - val_loss: 0.0499 - val_mse: 0.0073\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0471 - mse: 0.0064 - val_loss: 0.0504 - val_mse: 0.0069\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0468 - mse: 0.0063 - val_loss: 0.0488 - val_mse: 0.0067\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0467 - mse: 0.0063 - val_loss: 0.0566 - val_mse: 0.0082\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0473 - mse: 0.0065 - val_loss: 0.0493 - val_mse: 0.0069\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0465 - mse: 0.0062 - val_loss: 0.0483 - val_mse: 0.0065\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0464 - mse: 0.0062 - val_loss: 0.0486 - val_mse: 0.0068\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0464 - mse: 0.0061 - val_loss: 0.0496 - val_mse: 0.0067\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0463 - mse: 0.0061 - val_loss: 0.0510 - val_mse: 0.0071\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0459 - mse: 0.0060 - val_loss: 0.0492 - val_mse: 0.0067\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0464 - mse: 0.0062 - val_loss: 0.0468 - val_mse: 0.0064\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0461 - mse: 0.0060 - val_loss: 0.0494 - val_mse: 0.0069\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0458 - mse: 0.0060 - val_loss: 0.0504 - val_mse: 0.0074\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0459 - mse: 0.0060 - val_loss: 0.0499 - val_mse: 0.0073\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0461 - mse: 0.0061 - val_loss: 0.0478 - val_mse: 0.0064\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0458 - mse: 0.0060 - val_loss: 0.0511 - val_mse: 0.0076\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0459 - mse: 0.0060 - val_loss: 0.0471 - val_mse: 0.0062\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0457 - mse: 0.0059 - val_loss: 0.0502 - val_mse: 0.0066\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0455 - mse: 0.0059 - val_loss: 0.0471 - val_mse: 0.0063\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0454 - mse: 0.0058 - val_loss: 0.0460 - val_mse: 0.0061\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0457 - mse: 0.0059 - val_loss: 0.0468 - val_mse: 0.0063\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0453 - mse: 0.0058 - val_loss: 0.0497 - val_mse: 0.0071\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0454 - mse: 0.0058 - val_loss: 0.0489 - val_mse: 0.0065\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0461 - mse: 0.0061 - val_loss: 0.0491 - val_mse: 0.0071\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0462 - mse: 0.0061 - val_loss: 0.0502 - val_mse: 0.0072\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0459 - mse: 0.0060 - val_loss: 0.0484 - val_mse: 0.0067\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0452 - mse: 0.0058 - val_loss: 0.0485 - val_mse: 0.0065\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0452 - mse: 0.0058 - val_loss: 0.0475 - val_mse: 0.0065\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0449 - mse: 0.0057 - val_loss: 0.0495 - val_mse: 0.0070\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0451 - mse: 0.0058 - val_loss: 0.0482 - val_mse: 0.0069\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0450 - mse: 0.0058 - val_loss: 0.0485 - val_mse: 0.0067\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0447 - mse: 0.0056 - val_loss: 0.0474 - val_mse: 0.0064\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0456 - mse: 0.0059 - val_loss: 0.0485 - val_mse: 0.0068\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0454 - mse: 0.0058 - val_loss: 0.0470 - val_mse: 0.0065\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0451 - mse: 0.0057 - val_loss: 0.0467 - val_mse: 0.0062\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0455 - mse: 0.0059 - val_loss: 0.0489 - val_mse: 0.0069\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0450 - mse: 0.0057 - val_loss: 0.0528 - val_mse: 0.0076\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0451 - mse: 0.0058 - val_loss: 0.0473 - val_mse: 0.0064\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0446 - mse: 0.0056 - val_loss: 0.0461 - val_mse: 0.0060\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0443 - mse: 0.0056 - val_loss: 0.0460 - val_mse: 0.0060\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0445 - mse: 0.0056 - val_loss: 0.0468 - val_mse: 0.0061\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0443 - mse: 0.0056 - val_loss: 0.0460 - val_mse: 0.0059\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0451 - mse: 0.0058 - val_loss: 0.0472 - val_mse: 0.0063\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0448 - mse: 0.0057 - val_loss: 0.0482 - val_mse: 0.0066\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0450 - mse: 0.0057 - val_loss: 0.0487 - val_mse: 0.0067\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0442 - mse: 0.0055 - val_loss: 0.0480 - val_mse: 0.0069\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0450 - mse: 0.0057 - val_loss: 0.0491 - val_mse: 0.0069\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0444 - mse: 0.0056 - val_loss: 0.0472 - val_mse: 0.0062\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0442 - mse: 0.0055 - val_loss: 0.0478 - val_mse: 0.0065\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0055 - val_loss: 0.0477 - val_mse: 0.0065\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0443 - mse: 0.0056 - val_loss: 0.0466 - val_mse: 0.0061\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0055 - val_loss: 0.0483 - val_mse: 0.0065\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0445 - mse: 0.0056 - val_loss: 0.0515 - val_mse: 0.0078\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0449 - mse: 0.0057 - val_loss: 0.0488 - val_mse: 0.0065\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0444 - mse: 0.0056 - val_loss: 0.0462 - val_mse: 0.0061\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0445 - mse: 0.0056 - val_loss: 0.0461 - val_mse: 0.0061\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0445 - mse: 0.0056 - val_loss: 0.0472 - val_mse: 0.0065\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0055 - val_loss: 0.0490 - val_mse: 0.0069\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0436 - mse: 0.0053 - val_loss: 0.0463 - val_mse: 0.0062\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0439 - mse: 0.0054 - val_loss: 0.0464 - val_mse: 0.0061\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0437 - mse: 0.0054 - val_loss: 0.0483 - val_mse: 0.0065\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0445 - mse: 0.0056 - val_loss: 0.0481 - val_mse: 0.0063\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0440 - mse: 0.0055 - val_loss: 0.0462 - val_mse: 0.0061\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0440 - mse: 0.0055 - val_loss: 0.0461 - val_mse: 0.0061\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0438 - mse: 0.0054 - val_loss: 0.0462 - val_mse: 0.0063\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0439 - mse: 0.0054 - val_loss: 0.0482 - val_mse: 0.0064\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0443 - mse: 0.0055 - val_loss: 0.0468 - val_mse: 0.0063\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0436 - mse: 0.0054 - val_loss: 0.0472 - val_mse: 0.0063\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0438 - mse: 0.0054 - val_loss: 0.0453 - val_mse: 0.0058\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0442 - mse: 0.0055 - val_loss: 0.0457 - val_mse: 0.0060\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0439 - mse: 0.0054 - val_loss: 0.0479 - val_mse: 0.0066\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0440 - mse: 0.0055 - val_loss: 0.0472 - val_mse: 0.0062\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0433 - mse: 0.0053 - val_loss: 0.0463 - val_mse: 0.0061\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0435 - mse: 0.0053 - val_loss: 0.0466 - val_mse: 0.0061\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0432 - mse: 0.0053 - val_loss: 0.0466 - val_mse: 0.0063\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0438 - mse: 0.0054 - val_loss: 0.0459 - val_mse: 0.0060\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0434 - mse: 0.0053 - val_loss: 0.0462 - val_mse: 0.0061\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0436 - mse: 0.0053 - val_loss: 0.0471 - val_mse: 0.0063\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0435 - mse: 0.0053 - val_loss: 0.0488 - val_mse: 0.0068\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0437 - mse: 0.0053 - val_loss: 0.0474 - val_mse: 0.0064\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0431 - mse: 0.0052 - val_loss: 0.0469 - val_mse: 0.0062\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0431 - mse: 0.0052 - val_loss: 0.0473 - val_mse: 0.0065\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0435 - mse: 0.0053 - val_loss: 0.0493 - val_mse: 0.0068\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0435 - mse: 0.0053 - val_loss: 0.0465 - val_mse: 0.0061\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0430 - mse: 0.0052 - val_loss: 0.0463 - val_mse: 0.0061\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0430 - mse: 0.0052 - val_loss: 0.0491 - val_mse: 0.0068\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0426 - mse: 0.0051 - val_loss: 0.0461 - val_mse: 0.0061\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0428 - mse: 0.0051 - val_loss: 0.0450 - val_mse: 0.0059\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0428 - mse: 0.0051 - val_loss: 0.0441 - val_mse: 0.0056\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0436 - mse: 0.0054 - val_loss: 0.0452 - val_mse: 0.0060\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0427 - mse: 0.0051 - val_loss: 0.0481 - val_mse: 0.0065\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0426 - mse: 0.0051 - val_loss: 0.0452 - val_mse: 0.0059\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0429 - mse: 0.0051 - val_loss: 0.0480 - val_mse: 0.0067\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0427 - mse: 0.0051 - val_loss: 0.0458 - val_mse: 0.0060\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0426 - mse: 0.0051 - val_loss: 0.0458 - val_mse: 0.0061\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0428 - mse: 0.0051 - val_loss: 0.0470 - val_mse: 0.0063\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0428 - mse: 0.0051 - val_loss: 0.0474 - val_mse: 0.0062\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0427 - mse: 0.0051 - val_loss: 0.0480 - val_mse: 0.0064\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0428 - mse: 0.0051 - val_loss: 0.0463 - val_mse: 0.0062\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0428 - mse: 0.0051 - val_loss: 0.0459 - val_mse: 0.0060\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0432 - mse: 0.0052 - val_loss: 0.0450 - val_mse: 0.0059\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0431 - mse: 0.0052 - val_loss: 0.0485 - val_mse: 0.0066\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0430 - mse: 0.0052 - val_loss: 0.0449 - val_mse: 0.0057\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0429 - mse: 0.0051 - val_loss: 0.0443 - val_mse: 0.0056\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0428 - mse: 0.0051 - val_loss: 0.0433 - val_mse: 0.0055\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0425 - mse: 0.0050 - val_loss: 0.0494 - val_mse: 0.0068\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0428 - mse: 0.0051 - val_loss: 0.0486 - val_mse: 0.0071\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0430 - mse: 0.0052 - val_loss: 0.0440 - val_mse: 0.0055\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0428 - mse: 0.0051 - val_loss: 0.0438 - val_mse: 0.0056\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0419 - mse: 0.0049 - val_loss: 0.0454 - val_mse: 0.0059\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0423 - mse: 0.0050 - val_loss: 0.0462 - val_mse: 0.0063\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0420 - mse: 0.0049 - val_loss: 0.0488 - val_mse: 0.0068\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0421 - mse: 0.0049 - val_loss: 0.0442 - val_mse: 0.0056\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0422 - mse: 0.0050 - val_loss: 0.0467 - val_mse: 0.0061\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0416 - mse: 0.0048 - val_loss: 0.0424 - val_mse: 0.0053\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0417 - mse: 0.0048 - val_loss: 0.0456 - val_mse: 0.0059\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0415 - mse: 0.0048 - val_loss: 0.0434 - val_mse: 0.0055\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0416 - mse: 0.0048 - val_loss: 0.0422 - val_mse: 0.0052\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0414 - mse: 0.0047 - val_loss: 0.0439 - val_mse: 0.0056\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0418 - mse: 0.0049 - val_loss: 0.0453 - val_mse: 0.0063\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0047 - val_loss: 0.0479 - val_mse: 0.0063\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0416 - mse: 0.0048 - val_loss: 0.0431 - val_mse: 0.0054\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0412 - mse: 0.0047 - val_loss: 0.0419 - val_mse: 0.0052\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0047 - val_loss: 0.0427 - val_mse: 0.0054\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0411 - mse: 0.0047 - val_loss: 0.0424 - val_mse: 0.0053\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0419 - mse: 0.0049 - val_loss: 0.0439 - val_mse: 0.0058\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0411 - mse: 0.0047 - val_loss: 0.0434 - val_mse: 0.0056\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0047 - val_loss: 0.0441 - val_mse: 0.0056\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0414 - mse: 0.0048 - val_loss: 0.0435 - val_mse: 0.0054\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0413 - mse: 0.0048 - val_loss: 0.0423 - val_mse: 0.0054\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0407 - mse: 0.0046 - val_loss: 0.0418 - val_mse: 0.0051\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0421 - mse: 0.0049 - val_loss: 0.0425 - val_mse: 0.0053\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0411 - mse: 0.0047 - val_loss: 0.0427 - val_mse: 0.0055\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer2=keras.optimizers.Adam(learning_rate=.01) #optimal validation loss occured at learning rate = 0.1\n",
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=corrmatrix,\n",
    "    gc_layer_sizes=[16, 10],\n",
    "    gc_activations=[\"relu\", \"relu\"],\n",
    "    lstm_layer_sizes=[200, 200],\n",
    "    lstm_activations=[\"tanh\", \"tanh\"],\n",
    "    )\n",
    "x_input, x_output = gcn_lstm.in_out_tensors()\n",
    "\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "model.compile(optimizer=optimizer2, loss=\"mae\", metrics=[\"mse\"])\n",
    "history = model.fit(\n",
    "    trainX,\n",
    "    trainY,\n",
    "    epochs=150,\n",
    "    batch_size=200,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(valX, valY),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78f9577d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b90c8307",
    "outputId": "b66ad0bc-70c5-4bfa-a19d-2c198e5885ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 8, 10)]           0         \n",
      "_________________________________________________________________\n",
      "tf.expand_dims_1 (TFOpLambda (None, 8, 10, 1)          0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 8, 10)             0         \n",
      "_________________________________________________________________\n",
      "fixed_adjacency_graph_convol (None, 8, 16)             232       \n",
      "_________________________________________________________________\n",
      "fixed_adjacency_graph_convol (None, 8, 10)             232       \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 8, 10, 1)          0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 10, 8, 1)          0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 10, 8)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10, 200)           167200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 1608      \n",
      "=================================================================\n",
      "Total params: 490,072\n",
      "Trainable params: 489,944\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "[0.05519453436136246, 0.05353117361664772, 0.0534592866897583, 0.05172416567802429, 0.054770033806562424, 0.05220746994018555, 0.05288924649357796, 0.05327163636684418, 0.052057426422834396, 0.05111006274819374, 0.05028686672449112, 0.05003221705555916, 0.04832408204674721, 0.05059746652841568, 0.04892536625266075, 0.05141014605760574, 0.04916096851229668, 0.049877773970365524, 0.05040932819247246, 0.048848897218704224, 0.05658070743083954, 0.04925168678164482, 0.04832753166556358, 0.048583585768938065, 0.04964694008231163, 0.05097711831331253, 0.049231626093387604, 0.04677204787731171, 0.04936966300010681, 0.05039466544985771, 0.04989946633577347, 0.04780033975839615, 0.05110121890902519, 0.0471230149269104, 0.05022650584578514, 0.04706721380352974, 0.04596678912639618, 0.04676876217126846, 0.04972589761018753, 0.04888333007693291, 0.049115631729364395, 0.05016879364848137, 0.048387229442596436, 0.04850365221500397, 0.04746890440583229, 0.04949544742703438, 0.048179227858781815, 0.04851219058036804, 0.04742417111992836, 0.04854121804237366, 0.046959493309259415, 0.04674111679196358, 0.048859547823667526, 0.05281582474708557, 0.04734749346971512, 0.046085432171821594, 0.04599444568157196, 0.046789880841970444, 0.046047188341617584, 0.04718909412622452, 0.04820040240883827, 0.04865020513534546, 0.04795508459210396, 0.049062348902225494, 0.04719953238964081, 0.04777885973453522, 0.0477336049079895, 0.04657066613435745, 0.0482574999332428, 0.05145695060491562, 0.048769719898700714, 0.04616054520010948, 0.0461483933031559, 0.04717770218849182, 0.04904068261384964, 0.0463055744767189, 0.04643332585692406, 0.04826892912387848, 0.0481339655816555, 0.04619155079126358, 0.046109724789857864, 0.04620986059308052, 0.04820817708969116, 0.04682910442352295, 0.04721613973379135, 0.04533984139561653, 0.04571044445037842, 0.04791167005896568, 0.04722095653414726, 0.04628857225179672, 0.046615224331617355, 0.04659869149327278, 0.04593377932906151, 0.04621874541044235, 0.04712235927581787, 0.04877848923206329, 0.04742347449064255, 0.046854130923748016, 0.047275274991989136, 0.04934399202466011, 0.046485546976327896, 0.04630627483129501, 0.04911917448043823, 0.04610942304134369, 0.045010678470134735, 0.044139035046100616, 0.0451875738799572, 0.048149652779102325, 0.04517429694533348, 0.04802979901432991, 0.04576883092522621, 0.04575074464082718, 0.04697882756590843, 0.04737170785665512, 0.0480322390794754, 0.04628235101699829, 0.04585391283035278, 0.045007653534412384, 0.04853210970759392, 0.044856611639261246, 0.044336747378110886, 0.043320078402757645, 0.049421586096286774, 0.048635952174663544, 0.043996527791023254, 0.04382394999265671, 0.045419275760650635, 0.046240441501140594, 0.04879085347056389, 0.044244468212127686, 0.04669271409511566, 0.04241672158241272, 0.04559791833162308, 0.04343677684664726, 0.04215719550848007, 0.04388470575213432, 0.04526364430785179, 0.04794563353061676, 0.04313434287905693, 0.04187924042344093, 0.04272346943616867, 0.04240093380212784, 0.04386098310351372, 0.043393008410930634, 0.04412724822759628, 0.043486088514328, 0.04226425662636757, 0.041811875998973846, 0.04253629595041275, 0.04273902252316475]\n",
      "0.04273902252316475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/WBmodels/wb30/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/WBmodels/wb30/assets\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "print(history.history['val_loss'])\n",
    "print(history.history['val_loss'][149])\n",
    "loss30 = history.history['val_loss'][149]\n",
    "tloss30 = history.history['loss'][79]\n",
    "\n",
    "try:\n",
    "    os.makedirs('WBmodels')\n",
    "except OSError:\n",
    "    pass\n",
    "model.save(\"WBmodels/wb30\") # saving tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4c74bdc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "2OE_rJWdTqBs",
    "outputId": "71e8ce18-b4c7-4cd8-b063-062cc7c5ea5b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sg.utils.plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da419305",
   "metadata": {
    "id": "wAYNwaaKT2m_"
   },
   "outputs": [],
   "source": [
    "train_pred = model.predict(trainX)\n",
    "test_pred= model.predict(testX) #predicting test set\n",
    "mae = MeanAbsoluteError()\n",
    "testloss30=mae(testY,test_pred).numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f962a262",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OcFgUefVV7-",
    "outputId": "67245ca7-6782-448e-ca5f-6f5ebc00b6c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46329, 8)\n",
      "(9897, 8)\n",
      "Predicting values of first input of training data [0.02473848 0.5195126  0.0417733  0.6070952  0.05355102 0.4387005\n",
      " 0.05009508 0.6326354 ]\n",
      "Predicting values of first input of test data [0.01207857 0.5207263  0.0210062  0.607471   0.02539656 0.44233093\n",
      " 0.02351021 0.6341608 ]\n",
      "Predicting values of random input (2000) of test data [0.37667608 0.51222605 0.46034452 0.5912477  0.25212368 0.41313505\n",
      " 0.42924333 0.6240489 ]\n"
     ]
    }
   ],
   "source": [
    "print(train_pred.shape)\n",
    "print(test_pred.shape)\n",
    "print(\"Predicting values of first input of training data\", train_pred[0,:])\n",
    "print(\"Predicting values of first input of test data\",test_pred[0,:])\n",
    "\n",
    "print(\"Predicting values of random input (2000) of test data\",test_pred[2000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e857b9e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "k8hLEXWVUozV",
    "outputId": "3999306a-cc2e-45c7-93b4-2e4af7c971ee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##all test result visualization\n",
    "fig1 = plt.figure(figsize=(15, 8))\n",
    "#    ax1 = fig1.add_subplot(1,1,1)\n",
    "a_pred = test_pred[:, 6] #testing column 7, sensor 61 speed\n",
    "a_true = testY[:, 6]#testing column 7, sensor 61 speed\n",
    "\n",
    "plt.plot(a_true, \"b-\", label=\"true\")\n",
    "plt.plot(a_pred, \"r-\", label=\"prediction\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"speed\")\n",
    "plt.legend(loc=\"best\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3422522",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OjfUJqiPabNK",
    "outputId": "37d7740b-ccb9-44d5-f47f-818a1dfae65e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2  ...         5         6         7\n",
      "0  0.012079  0.520726  0.021006  ...  0.442331  0.023510  0.634161\n",
      "1  0.012375  0.520797  0.021486  ...  0.442373  0.024152  0.634353\n",
      "2  0.012025  0.520927  0.020890  ...  0.442681  0.023440  0.634549\n",
      "3  0.011439  0.520999  0.019918  ...  0.442971  0.022220  0.634605\n",
      "4  0.011299  0.521015  0.019699  ...  0.443059  0.021985  0.634631\n",
      "\n",
      "[5 rows x 8 columns]\n",
      "   063Volume  063Speed  051Volume  ...  031Speed  003Volume  003Speed\n",
      "0          1        98          3  ...        97          3        92\n",
      "1          1        98          3  ...        97          3        92\n",
      "2          1        98          3  ...        97          3        93\n",
      "3          1        98          2  ...        97          3        93\n",
      "4          1        98          2  ...        97          3        93\n",
      "\n",
      "[5 rows x 8 columns]\n",
      "   063Volume  063Speed  051Volume  ...  031Speed  003Volume  003Speed\n",
      "0          0       104          1  ...        97          3        89\n",
      "1          1       102          5  ...        98          2        99\n",
      "2          2        94          0  ...        97          2        87\n",
      "3          1        94          1  ...        96          2        95\n",
      "4          4        65          5  ...        99          0        95\n",
      "\n",
      "[5 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#converting predicitons and truths back into a data frame\n",
    "test_preddf = pd.DataFrame(test_pred)\n",
    "testY_df = pd.DataFrame(testY) \n",
    "#reversing scaling process to turn predictions and truths back into real units\n",
    "testY_unscaled = pd.DataFrame(min_max_scaler.inverse_transform(testY_df))\n",
    "print(test_preddf.head())\n",
    "unscaledoutput = pd.DataFrame(min_max_scaler.inverse_transform(test_preddf))\n",
    "#getting column names from the original dataset and converting real units into integers(volume only makes sense as an integer)\n",
    "unscaledoutput.columns = dataset.columns\n",
    "unscaledoutput = unscaledoutput.astype(int)\n",
    "print(unscaledoutput.head())\n",
    "testY_unscaled.columns=dataset.columns\n",
    "testY_unscaled = testY_unscaled.astype(int)\n",
    "\n",
    "\n",
    "print(testY_unscaled.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18ff8c83",
   "metadata": {
    "id": "SL_Aa5LdkC8u"
   },
   "outputs": [],
   "source": [
    "#saving truths and predictions to file for plotting later\n",
    "try:\n",
    "    os.makedirs('predictions')\n",
    "except OSError:\n",
    "    pass\n",
    "try:\n",
    "    os.makedirs('truths')\n",
    "except OSError:\n",
    "    pass\n",
    "unscaledoutput.to_csv('predictions/wb30minpred.csv')\n",
    "testY_unscaled.to_csv('truths/wb30.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f291d",
   "metadata": {
    "id": "cP3YqjyvUmAM"
   },
   "source": [
    "Hyperparameter tuned for 30 min prediction. Will use same hyperparameter settings for all prediction lengths. Process will be repeated in each cell for each prediction length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "672e63b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThQotvt2U_wa",
    "outputId": "25c8741c-a108-488d-9b19-b681c7401611"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "232/232 [==============================] - 8s 21ms/step - loss: 0.0552 - mse: 0.0086 - val_loss: 0.0519 - val_mse: 0.0077\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0451 - mse: 0.0057 - val_loss: 0.0483 - val_mse: 0.0066\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0430 - mse: 0.0051 - val_loss: 0.0469 - val_mse: 0.0061\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0423 - mse: 0.0049 - val_loss: 0.0458 - val_mse: 0.0057\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0418 - mse: 0.0049 - val_loss: 0.0457 - val_mse: 0.0057\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0415 - mse: 0.0048 - val_loss: 0.0450 - val_mse: 0.0057\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0411 - mse: 0.0047 - val_loss: 0.0441 - val_mse: 0.0054\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0409 - mse: 0.0046 - val_loss: 0.0446 - val_mse: 0.0054\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0407 - mse: 0.0046 - val_loss: 0.0452 - val_mse: 0.0054\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0045 - val_loss: 0.0446 - val_mse: 0.0053\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0404 - mse: 0.0045 - val_loss: 0.0427 - val_mse: 0.0049\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0403 - mse: 0.0045 - val_loss: 0.0407 - val_mse: 0.0044\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0400 - mse: 0.0044 - val_loss: 0.0432 - val_mse: 0.0051\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0402 - mse: 0.0044 - val_loss: 0.0424 - val_mse: 0.0049\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0401 - mse: 0.0045 - val_loss: 0.0428 - val_mse: 0.0049\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0400 - mse: 0.0044 - val_loss: 0.0427 - val_mse: 0.0051\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0398 - mse: 0.0044 - val_loss: 0.0411 - val_mse: 0.0047\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0398 - mse: 0.0044 - val_loss: 0.0418 - val_mse: 0.0046\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0398 - mse: 0.0044 - val_loss: 0.0405 - val_mse: 0.0046\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0395 - mse: 0.0043 - val_loss: 0.0403 - val_mse: 0.0044\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0393 - mse: 0.0042 - val_loss: 0.0418 - val_mse: 0.0048\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0394 - mse: 0.0042 - val_loss: 0.0440 - val_mse: 0.0051\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0393 - mse: 0.0042 - val_loss: 0.0420 - val_mse: 0.0050\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0393 - mse: 0.0042 - val_loss: 0.0428 - val_mse: 0.0049\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0391 - mse: 0.0042 - val_loss: 0.0418 - val_mse: 0.0047\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0391 - mse: 0.0042 - val_loss: 0.0418 - val_mse: 0.0047\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0392 - mse: 0.0042 - val_loss: 0.0402 - val_mse: 0.0043\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0388 - mse: 0.0041 - val_loss: 0.0410 - val_mse: 0.0048\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0388 - mse: 0.0041 - val_loss: 0.0401 - val_mse: 0.0045\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0397 - mse: 0.0044 - val_loss: 0.0437 - val_mse: 0.0053\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0392 - mse: 0.0042 - val_loss: 0.0422 - val_mse: 0.0050\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0388 - mse: 0.0041 - val_loss: 0.0383 - val_mse: 0.0043\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0387 - mse: 0.0041 - val_loss: 0.0405 - val_mse: 0.0046\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0386 - mse: 0.0041 - val_loss: 0.0399 - val_mse: 0.0044\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0387 - mse: 0.0041 - val_loss: 0.0405 - val_mse: 0.0046\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0384 - mse: 0.0040 - val_loss: 0.0389 - val_mse: 0.0042\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0385 - mse: 0.0040 - val_loss: 0.0412 - val_mse: 0.0048\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0377 - mse: 0.0039 - val_loss: 0.0374 - val_mse: 0.0041\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0379 - mse: 0.0039 - val_loss: 0.0398 - val_mse: 0.0043\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0380 - mse: 0.0039 - val_loss: 0.0409 - val_mse: 0.0047\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0375 - mse: 0.0038 - val_loss: 0.0374 - val_mse: 0.0039\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0375 - mse: 0.0038 - val_loss: 0.0372 - val_mse: 0.0040\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0373 - mse: 0.0038 - val_loss: 0.0357 - val_mse: 0.0037\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0368 - mse: 0.0037 - val_loss: 0.0368 - val_mse: 0.0038\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0374 - mse: 0.0038 - val_loss: 0.0381 - val_mse: 0.0041\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0373 - mse: 0.0038 - val_loss: 0.0368 - val_mse: 0.0039\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0369 - mse: 0.0037 - val_loss: 0.0373 - val_mse: 0.0040\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0366 - mse: 0.0037 - val_loss: 0.0380 - val_mse: 0.0041\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0368 - mse: 0.0037 - val_loss: 0.0371 - val_mse: 0.0039\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0368 - mse: 0.0037 - val_loss: 0.0366 - val_mse: 0.0038\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0366 - mse: 0.0037 - val_loss: 0.0356 - val_mse: 0.0037\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0365 - mse: 0.0036 - val_loss: 0.0350 - val_mse: 0.0037\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0354 - val_mse: 0.0038\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0366 - mse: 0.0037 - val_loss: 0.0363 - val_mse: 0.0039\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0369 - mse: 0.0037 - val_loss: 0.0361 - val_mse: 0.0038\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0363 - mse: 0.0036 - val_loss: 0.0367 - val_mse: 0.0040\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0363 - mse: 0.0036 - val_loss: 0.0356 - val_mse: 0.0038\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0366 - val_mse: 0.0039\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0373 - val_mse: 0.0040\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0351 - val_mse: 0.0037\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0363 - mse: 0.0036 - val_loss: 0.0349 - val_mse: 0.0036\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0365 - mse: 0.0036 - val_loss: 0.0350 - val_mse: 0.0038\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0363 - mse: 0.0036 - val_loss: 0.0349 - val_mse: 0.0036\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0362 - mse: 0.0036 - val_loss: 0.0353 - val_mse: 0.0038\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0352 - val_mse: 0.0037\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0361 - mse: 0.0036 - val_loss: 0.0345 - val_mse: 0.0036\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0369 - mse: 0.0037 - val_loss: 0.0423 - val_mse: 0.0050\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0360 - val_mse: 0.0039\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0365 - mse: 0.0036 - val_loss: 0.0364 - val_mse: 0.0039\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0358 - val_mse: 0.0037\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0361 - mse: 0.0036 - val_loss: 0.0384 - val_mse: 0.0043\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 4s 16ms/step - loss: 0.0362 - mse: 0.0036 - val_loss: 0.0349 - val_mse: 0.0038\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0350 - val_mse: 0.0037\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0363 - mse: 0.0036 - val_loss: 0.0343 - val_mse: 0.0036\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0358 - val_mse: 0.0038\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0361 - mse: 0.0035 - val_loss: 0.0351 - val_mse: 0.0036\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0361 - mse: 0.0036 - val_loss: 0.0357 - val_mse: 0.0038\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0361 - mse: 0.0036 - val_loss: 0.0347 - val_mse: 0.0036\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0360 - mse: 0.0036 - val_loss: 0.0353 - val_mse: 0.0038\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0377 - mse: 0.0039 - val_loss: 0.0418 - val_mse: 0.0048\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0371 - mse: 0.0037 - val_loss: 0.0352 - val_mse: 0.0037\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0354 - val_mse: 0.0039\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0361 - mse: 0.0036 - val_loss: 0.0345 - val_mse: 0.0036\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0434 - val_mse: 0.0052\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0368 - mse: 0.0037 - val_loss: 0.0363 - val_mse: 0.0038\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0369 - mse: 0.0037 - val_loss: 0.0385 - val_mse: 0.0042\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0363 - mse: 0.0036 - val_loss: 0.0351 - val_mse: 0.0037\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0427 - val_mse: 0.0049\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0361 - mse: 0.0035 - val_loss: 0.0350 - val_mse: 0.0036\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0363 - mse: 0.0036 - val_loss: 0.0347 - val_mse: 0.0036\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0347 - val_mse: 0.0036\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0354 - val_mse: 0.0037\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0354 - val_mse: 0.0038\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0350 - val_mse: 0.0036\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0344 - val_mse: 0.0036\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0374 - mse: 0.0038 - val_loss: 0.0371 - val_mse: 0.0040\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0384 - val_mse: 0.0044\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0358 - mse: 0.0035 - val_loss: 0.0355 - val_mse: 0.0040\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0361 - val_mse: 0.0039\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0365 - mse: 0.0037 - val_loss: 0.0429 - val_mse: 0.0051\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0377 - mse: 0.0039 - val_loss: 0.0345 - val_mse: 0.0036\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0373 - mse: 0.0038 - val_loss: 0.0404 - val_mse: 0.0045\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0372 - mse: 0.0038 - val_loss: 0.0347 - val_mse: 0.0035\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0372 - mse: 0.0038 - val_loss: 0.0403 - val_mse: 0.0046\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0375 - mse: 0.0038 - val_loss: 0.0357 - val_mse: 0.0036\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0362 - mse: 0.0036 - val_loss: 0.0353 - val_mse: 0.0037\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0358 - mse: 0.0035 - val_loss: 0.0341 - val_mse: 0.0035\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0343 - val_mse: 0.0035\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0361 - val_mse: 0.0038\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0359 - val_mse: 0.0037\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0362 - mse: 0.0036 - val_loss: 0.0338 - val_mse: 0.0034\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0354 - val_mse: 0.0037\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0356 - mse: 0.0034 - val_loss: 0.0346 - val_mse: 0.0036\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0335 - val_mse: 0.0034\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0356 - mse: 0.0034 - val_loss: 0.0345 - val_mse: 0.0037\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0372 - mse: 0.0037 - val_loss: 0.0339 - val_mse: 0.0035\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0355 - mse: 0.0034 - val_loss: 0.0341 - val_mse: 0.0035\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0351 - val_mse: 0.0037\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0357 - mse: 0.0035 - val_loss: 0.0346 - val_mse: 0.0036\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0356 - mse: 0.0035 - val_loss: 0.0351 - val_mse: 0.0036\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0357 - mse: 0.0035 - val_loss: 0.0338 - val_mse: 0.0035\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0365 - mse: 0.0036 - val_loss: 0.0339 - val_mse: 0.0034\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0357 - mse: 0.0035 - val_loss: 0.0340 - val_mse: 0.0035\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0356 - mse: 0.0034 - val_loss: 0.0339 - val_mse: 0.0035\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0356 - mse: 0.0034 - val_loss: 0.0346 - val_mse: 0.0035\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0356 - mse: 0.0034 - val_loss: 0.0346 - val_mse: 0.0036\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0361 - mse: 0.0035 - val_loss: 0.0352 - val_mse: 0.0038\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0354 - mse: 0.0034 - val_loss: 0.0338 - val_mse: 0.0034\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0355 - mse: 0.0034 - val_loss: 0.0341 - val_mse: 0.0035\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0356 - mse: 0.0034 - val_loss: 0.0346 - val_mse: 0.0036\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0358 - mse: 0.0035 - val_loss: 0.0338 - val_mse: 0.0035\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0353 - mse: 0.0034 - val_loss: 0.0337 - val_mse: 0.0034\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0358 - mse: 0.0035 - val_loss: 0.0344 - val_mse: 0.0035\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0354 - mse: 0.0034 - val_loss: 0.0347 - val_mse: 0.0035\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0355 - mse: 0.0034 - val_loss: 0.0342 - val_mse: 0.0035\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0354 - mse: 0.0034 - val_loss: 0.0349 - val_mse: 0.0036\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0354 - mse: 0.0034 - val_loss: 0.0340 - val_mse: 0.0034\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0356 - mse: 0.0034 - val_loss: 0.0369 - val_mse: 0.0038\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0353 - mse: 0.0033 - val_loss: 0.0342 - val_mse: 0.0034\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0354 - mse: 0.0034 - val_loss: 0.0339 - val_mse: 0.0035\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0352 - mse: 0.0033 - val_loss: 0.0368 - val_mse: 0.0039\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0355 - mse: 0.0034 - val_loss: 0.0338 - val_mse: 0.0034\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0356 - mse: 0.0034 - val_loss: 0.0339 - val_mse: 0.0035\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0354 - mse: 0.0034 - val_loss: 0.0337 - val_mse: 0.0033\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0352 - mse: 0.0033 - val_loss: 0.0441 - val_mse: 0.0053\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0352 - mse: 0.0033 - val_loss: 0.0355 - val_mse: 0.0036\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0357 - mse: 0.0034 - val_loss: 0.0344 - val_mse: 0.0035\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0352 - mse: 0.0033 - val_loss: 0.0336 - val_mse: 0.0034\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0353 - mse: 0.0033 - val_loss: 0.0343 - val_mse: 0.0035\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0355 - mse: 0.0034 - val_loss: 0.0336 - val_mse: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/WBmodels/wb5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/WBmodels/wb5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2  ...         5         6         7\n",
      "0  0.011061  0.519162  0.020542  ...  0.438946  0.024011  0.629961\n",
      "1  0.010956  0.519153  0.020350  ...  0.438952  0.023695  0.630043\n",
      "2  0.008927  0.519374  0.016897  ...  0.439709  0.019846  0.629705\n",
      "3  0.008822  0.519347  0.016633  ...  0.439881  0.019449  0.630418\n",
      "4  0.007969  0.519587  0.015055  ...  0.440592  0.017579  0.630821\n",
      "\n",
      "[5 rows x 8 columns]\n",
      "   063Volume  063Speed  051Volume  ...  031Speed  003Volume  003Speed\n",
      "0          1        98          3  ...        96          3        92\n",
      "1          1        98          3  ...        96          3        92\n",
      "2          0        98          2  ...        97          3        92\n",
      "3          0        98          2  ...        97          3        92\n",
      "4          0        98          2  ...        97          2        92\n",
      "\n",
      "[5 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10 #length of data used for the prediction, currently using the last 10 mins of data\n",
    "pre_len = 5 # distance of prediction, currently predicting speeds and volumes 30 mins from now\n",
    "\n",
    "#feature extractions using next prediction length\n",
    "train5X, train5Y,val5X,val5Y, test5X, test5Y = sequence_data_preparation(\n",
    "    seq_len, pre_len, train_data_t, val_data_t,test_data_t)\n",
    "\n",
    "optimizer2=keras.optimizers.Adam(learning_rate=.01) #using tuned hyperparameters\n",
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=corrmatrix,\n",
    "    gc_layer_sizes=[16, 10],\n",
    "    gc_activations=[\"relu\", \"relu\"],\n",
    "    lstm_layer_sizes=[200, 200],\n",
    "    lstm_activations=[\"tanh\", \"tanh\"],\n",
    "    )# redefining model\n",
    "x_input, x_output = gcn_lstm.in_out_tensors()\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "model.compile(optimizer=optimizer2, loss=\"mae\", metrics=[\"mse\"])\n",
    "history = model.fit(\n",
    "    train5X,\n",
    "    train5Y,\n",
    "    epochs=150,\n",
    "    batch_size=200,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(val5X, val5Y),\n",
    ")#training model on new dataset with preselected hyperparameters\n",
    "#saving training and validation loss at training completion\n",
    "loss5 = history.history['val_loss'][149]\n",
    "tloss5 = history.history['loss'][149]\n",
    "model.save(\"WBmodels/wb5\")\n",
    "train_5pred = model.predict(train5X)\n",
    "test_5pred= model.predict(test5X)\n",
    "testloss5=mae(test5Y,test_5pred).numpy()\n",
    "\n",
    "test5pred_t = test_5pred.transpose()\n",
    "test_5preddf = pd.DataFrame(test_5pred)\n",
    "print(test_5preddf.head())\n",
    "unscaledoutput5 = pd.DataFrame(min_max_scaler.inverse_transform(test_5preddf))\n",
    "unscaledoutput5.columns = dataset.columns\n",
    "unscaledoutput5 = unscaledoutput5.astype(int)\n",
    "print(unscaledoutput5.head())\n",
    "unscaledoutput5.to_csv('predictions/wb5minpred.csv')\n",
    "test5Y_df = pd.DataFrame(test5Y)\n",
    "test5Y_unscaled = pd.DataFrame(min_max_scaler.inverse_transform(test5Y_df))\n",
    "test5Y_unscaled.columns=dataset.columns\n",
    "test5Y_unscaled = test5Y_unscaled.astype(int)\n",
    "test5Y_unscaled.to_csv('truths/wb5.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05ec980f",
   "metadata": {
    "id": "le_fVIOQqjvX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58124d6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pfm05pO3aygU",
    "outputId": "4ad4f6dd-0035-464f-98cd-07ffbcdcfa7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "232/232 [==============================] - 9s 22ms/step - loss: 0.0557 - mse: 0.0085 - val_loss: 0.0515 - val_mse: 0.0076\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0457 - mse: 0.0058 - val_loss: 0.0499 - val_mse: 0.0069\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0440 - mse: 0.0054 - val_loss: 0.0478 - val_mse: 0.0064\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0433 - mse: 0.0052 - val_loss: 0.0472 - val_mse: 0.0061\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0429 - mse: 0.0051 - val_loss: 0.0464 - val_mse: 0.0060\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0427 - mse: 0.0051 - val_loss: 0.0470 - val_mse: 0.0059\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0423 - mse: 0.0050 - val_loss: 0.0463 - val_mse: 0.0059\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0423 - mse: 0.0050 - val_loss: 0.0450 - val_mse: 0.0055\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0420 - mse: 0.0049 - val_loss: 0.0441 - val_mse: 0.0054\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0420 - mse: 0.0049 - val_loss: 0.0434 - val_mse: 0.0051\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0418 - mse: 0.0049 - val_loss: 0.0460 - val_mse: 0.0058\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0417 - mse: 0.0049 - val_loss: 0.0472 - val_mse: 0.0060\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0420 - mse: 0.0049 - val_loss: 0.0433 - val_mse: 0.0053\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0416 - mse: 0.0048 - val_loss: 0.0430 - val_mse: 0.0051\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0417 - mse: 0.0048 - val_loss: 0.0442 - val_mse: 0.0054\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0414 - mse: 0.0048 - val_loss: 0.0460 - val_mse: 0.0057\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0414 - mse: 0.0048 - val_loss: 0.0428 - val_mse: 0.0049\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0047 - val_loss: 0.0430 - val_mse: 0.0052\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0411 - mse: 0.0047 - val_loss: 0.0432 - val_mse: 0.0051\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0409 - mse: 0.0046 - val_loss: 0.0419 - val_mse: 0.0047\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0046 - val_loss: 0.0428 - val_mse: 0.0049\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0412 - mse: 0.0047 - val_loss: 0.0430 - val_mse: 0.0050\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0048 - val_loss: 0.0430 - val_mse: 0.0051\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0409 - mse: 0.0047 - val_loss: 0.0428 - val_mse: 0.0048\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0409 - mse: 0.0046 - val_loss: 0.0427 - val_mse: 0.0049\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0407 - mse: 0.0046 - val_loss: 0.0446 - val_mse: 0.0052\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0405 - mse: 0.0045 - val_loss: 0.0417 - val_mse: 0.0046\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0045 - val_loss: 0.0434 - val_mse: 0.0051\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0405 - mse: 0.0045 - val_loss: 0.0429 - val_mse: 0.0049\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0404 - mse: 0.0045 - val_loss: 0.0421 - val_mse: 0.0049\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0402 - mse: 0.0045 - val_loss: 0.0411 - val_mse: 0.0045\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0403 - mse: 0.0045 - val_loss: 0.0420 - val_mse: 0.0047\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0401 - mse: 0.0044 - val_loss: 0.0425 - val_mse: 0.0049\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0401 - mse: 0.0044 - val_loss: 0.0426 - val_mse: 0.0050\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0402 - mse: 0.0044 - val_loss: 0.0420 - val_mse: 0.0048\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0046 - val_loss: 0.0438 - val_mse: 0.0054\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0407 - mse: 0.0046 - val_loss: 0.0441 - val_mse: 0.0052\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0404 - mse: 0.0045 - val_loss: 0.0409 - val_mse: 0.0047\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0399 - mse: 0.0044 - val_loss: 0.0416 - val_mse: 0.0046\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0399 - mse: 0.0044 - val_loss: 0.0418 - val_mse: 0.0048\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0400 - mse: 0.0044 - val_loss: 0.0421 - val_mse: 0.0048\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0399 - mse: 0.0044 - val_loss: 0.0420 - val_mse: 0.0048\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0399 - mse: 0.0044 - val_loss: 0.0407 - val_mse: 0.0045\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0397 - mse: 0.0043 - val_loss: 0.0413 - val_mse: 0.0046\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0397 - mse: 0.0043 - val_loss: 0.0413 - val_mse: 0.0046\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0395 - mse: 0.0043 - val_loss: 0.0420 - val_mse: 0.0048\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0396 - mse: 0.0043 - val_loss: 0.0412 - val_mse: 0.0045\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0397 - mse: 0.0043 - val_loss: 0.0406 - val_mse: 0.0045\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0395 - mse: 0.0043 - val_loss: 0.0430 - val_mse: 0.0049\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0394 - mse: 0.0043 - val_loss: 0.0413 - val_mse: 0.0046\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0396 - mse: 0.0043 - val_loss: 0.0399 - val_mse: 0.0043\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0395 - mse: 0.0043 - val_loss: 0.0424 - val_mse: 0.0048\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0394 - mse: 0.0043 - val_loss: 0.0441 - val_mse: 0.0053\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0393 - mse: 0.0042 - val_loss: 0.0410 - val_mse: 0.0046\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0394 - mse: 0.0042 - val_loss: 0.0412 - val_mse: 0.0046\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0393 - mse: 0.0043 - val_loss: 0.0407 - val_mse: 0.0045\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0393 - mse: 0.0042 - val_loss: 0.0418 - val_mse: 0.0047\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0392 - mse: 0.0042 - val_loss: 0.0416 - val_mse: 0.0047\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0393 - mse: 0.0043 - val_loss: 0.0416 - val_mse: 0.0047\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0392 - mse: 0.0042 - val_loss: 0.0409 - val_mse: 0.0046\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0391 - mse: 0.0042 - val_loss: 0.0413 - val_mse: 0.0047\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0392 - mse: 0.0042 - val_loss: 0.0434 - val_mse: 0.0051\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0393 - mse: 0.0042 - val_loss: 0.0412 - val_mse: 0.0046\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0391 - mse: 0.0042 - val_loss: 0.0404 - val_mse: 0.0045\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0392 - mse: 0.0042 - val_loss: 0.0402 - val_mse: 0.0044\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0391 - mse: 0.0042 - val_loss: 0.0409 - val_mse: 0.0045\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0396 - mse: 0.0043 - val_loss: 0.0412 - val_mse: 0.0046\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0390 - mse: 0.0042 - val_loss: 0.0408 - val_mse: 0.0045\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0391 - mse: 0.0042 - val_loss: 0.0411 - val_mse: 0.0046\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0390 - mse: 0.0042 - val_loss: 0.0445 - val_mse: 0.0053\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0388 - mse: 0.0041 - val_loss: 0.0428 - val_mse: 0.0049\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0386 - mse: 0.0041 - val_loss: 0.0386 - val_mse: 0.0041\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0388 - mse: 0.0041 - val_loss: 0.0405 - val_mse: 0.0045\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0389 - mse: 0.0041 - val_loss: 0.0459 - val_mse: 0.0058\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0389 - mse: 0.0041 - val_loss: 0.0380 - val_mse: 0.0041\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0389 - mse: 0.0041 - val_loss: 0.0406 - val_mse: 0.0046\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0381 - mse: 0.0039 - val_loss: 0.0380 - val_mse: 0.0039\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0382 - mse: 0.0040 - val_loss: 0.0385 - val_mse: 0.0041\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0384 - mse: 0.0040 - val_loss: 0.0373 - val_mse: 0.0039\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0378 - mse: 0.0039 - val_loss: 0.0360 - val_mse: 0.0037\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0378 - mse: 0.0039 - val_loss: 0.0364 - val_mse: 0.0039\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0380 - mse: 0.0039 - val_loss: 0.0386 - val_mse: 0.0041\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0374 - mse: 0.0038 - val_loss: 0.0363 - val_mse: 0.0040\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0374 - mse: 0.0038 - val_loss: 0.0394 - val_mse: 0.0042\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0375 - mse: 0.0039 - val_loss: 0.0372 - val_mse: 0.0038\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0372 - mse: 0.0038 - val_loss: 0.0355 - val_mse: 0.0036\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0370 - mse: 0.0038 - val_loss: 0.0366 - val_mse: 0.0038\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0375 - mse: 0.0038 - val_loss: 0.0359 - val_mse: 0.0037\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0370 - mse: 0.0037 - val_loss: 0.0393 - val_mse: 0.0043\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0370 - mse: 0.0037 - val_loss: 0.0357 - val_mse: 0.0036\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0367 - mse: 0.0037 - val_loss: 0.0355 - val_mse: 0.0036\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0366 - mse: 0.0036 - val_loss: 0.0354 - val_mse: 0.0036\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0373 - mse: 0.0038 - val_loss: 0.0358 - val_mse: 0.0036\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0367 - mse: 0.0037 - val_loss: 0.0374 - val_mse: 0.0039\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0366 - mse: 0.0036 - val_loss: 0.0355 - val_mse: 0.0036\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0367 - mse: 0.0037 - val_loss: 0.0355 - val_mse: 0.0037\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0370 - mse: 0.0037 - val_loss: 0.0384 - val_mse: 0.0041\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0366 - mse: 0.0036 - val_loss: 0.0351 - val_mse: 0.0035\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0369 - mse: 0.0037 - val_loss: 0.0364 - val_mse: 0.0037\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0358 - val_mse: 0.0037\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0368 - mse: 0.0037 - val_loss: 0.0352 - val_mse: 0.0035\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0367 - mse: 0.0037 - val_loss: 0.0383 - val_mse: 0.0041\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0365 - mse: 0.0036 - val_loss: 0.0352 - val_mse: 0.0036\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0363 - mse: 0.0036 - val_loss: 0.0350 - val_mse: 0.0036\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0371 - val_mse: 0.0038\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0365 - mse: 0.0036 - val_loss: 0.0361 - val_mse: 0.0037\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0363 - mse: 0.0036 - val_loss: 0.0349 - val_mse: 0.0035\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0367 - mse: 0.0036 - val_loss: 0.0353 - val_mse: 0.0036\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0365 - mse: 0.0036 - val_loss: 0.0354 - val_mse: 0.0037\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0366 - mse: 0.0036 - val_loss: 0.0351 - val_mse: 0.0035\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0363 - val_mse: 0.0038\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0363 - mse: 0.0036 - val_loss: 0.0366 - val_mse: 0.0037\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0362 - mse: 0.0035 - val_loss: 0.0350 - val_mse: 0.0036\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0365 - val_mse: 0.0037\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0365 - mse: 0.0036 - val_loss: 0.0364 - val_mse: 0.0037\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0366 - val_mse: 0.0037\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0363 - mse: 0.0035 - val_loss: 0.0359 - val_mse: 0.0037\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0352 - val_mse: 0.0036\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0361 - mse: 0.0035 - val_loss: 0.0352 - val_mse: 0.0036\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0348 - val_mse: 0.0036\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0362 - mse: 0.0036 - val_loss: 0.0365 - val_mse: 0.0037\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0361 - mse: 0.0035 - val_loss: 0.0357 - val_mse: 0.0037\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0361 - mse: 0.0035 - val_loss: 0.0349 - val_mse: 0.0035\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0361 - mse: 0.0035 - val_loss: 0.0353 - val_mse: 0.0036\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0362 - mse: 0.0035 - val_loss: 0.0358 - val_mse: 0.0036\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0354 - val_mse: 0.0036\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0351 - val_mse: 0.0036\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0360 - val_mse: 0.0037\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0348 - val_mse: 0.0035\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0364 - mse: 0.0036 - val_loss: 0.0362 - val_mse: 0.0037\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0347 - val_mse: 0.0035\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0358 - mse: 0.0035 - val_loss: 0.0352 - val_mse: 0.0035\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0352 - val_mse: 0.0036\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0351 - val_mse: 0.0036\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0361 - mse: 0.0035 - val_loss: 0.0354 - val_mse: 0.0037\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0354 - val_mse: 0.0036\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0358 - mse: 0.0034 - val_loss: 0.0363 - val_mse: 0.0038\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0374 - val_mse: 0.0039\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0369 - mse: 0.0037 - val_loss: 0.0362 - val_mse: 0.0037\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0356 - val_mse: 0.0035\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0352 - val_mse: 0.0036\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0392 - val_mse: 0.0042\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0370 - val_mse: 0.0039\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0361 - mse: 0.0035 - val_loss: 0.0348 - val_mse: 0.0035\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0358 - mse: 0.0034 - val_loss: 0.0354 - val_mse: 0.0036\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0357 - mse: 0.0034 - val_loss: 0.0351 - val_mse: 0.0036\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0360 - val_mse: 0.0037\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0359 - mse: 0.0035 - val_loss: 0.0350 - val_mse: 0.0035\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0360 - mse: 0.0035 - val_loss: 0.0349 - val_mse: 0.0035\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0357 - mse: 0.0034 - val_loss: 0.0367 - val_mse: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/WBmodels/wb10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/WBmodels/wb10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2  ...         5         6         7\n",
      "0  0.012698  0.518548  0.023568  ...  0.445396  0.029368  0.642226\n",
      "1  0.012749  0.518484  0.023414  ...  0.445272  0.029163  0.642587\n",
      "2  0.011694  0.518490  0.021702  ...  0.445436  0.026972  0.642585\n",
      "3  0.011158  0.518607  0.020603  ...  0.446241  0.025270  0.643133\n",
      "4  0.011135  0.518670  0.020399  ...  0.446975  0.024777  0.644040\n",
      "\n",
      "[5 rows x 8 columns]\n",
      "   063Volume  063Speed  051Volume  ...  031Speed  003Volume  003Speed\n",
      "0          1        98          3  ...        97          4        94\n",
      "1          1        98          3  ...        97          4        94\n",
      "2          1        98          3  ...        97          4        94\n",
      "3          1        98          3  ...        98          3        94\n",
      "4          1        98          3  ...        98          3        94\n",
      "\n",
      "[5 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10 #length of data used for the prediction, currently using the last 10 mins of data\n",
    "pre_len = 10 # distance of prediction, currently predicting speeds and volumes 30 mins from now\n",
    "\n",
    "train10X, train10Y,val10X,val10Y, test10X, test10Y = sequence_data_preparation(\n",
    "    seq_len, pre_len, train_data_t, val_data_t,test_data_t)\n",
    "\n",
    "optimizer2=keras.optimizers.Adam(learning_rate=.01)\n",
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=corrmatrix,\n",
    "    gc_layer_sizes=[16, 10],\n",
    "    gc_activations=[\"relu\", \"relu\"],\n",
    "    lstm_layer_sizes=[200, 200],\n",
    "    lstm_activations=[\"tanh\", \"tanh\"],\n",
    "    )\n",
    "x_input, x_output = gcn_lstm.in_out_tensors()\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "model.compile(optimizer=optimizer2, loss=\"mae\", metrics=[\"mse\"])\n",
    "history = model.fit(\n",
    "    train10X,\n",
    "    train10Y,\n",
    "    epochs=150,\n",
    "    batch_size=200,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(val10X, val10Y),\n",
    ")\n",
    "loss10 = history.history['val_loss'][149]\n",
    "tloss10 = history.history['loss'][149]\n",
    "model.save(\"WBmodels/wb10\")\n",
    "train_10pred = model.predict(train10X)\n",
    "test_10pred= model.predict(test10X)\n",
    "testloss10=mae(test10Y,test_10pred).numpy()\n",
    "\n",
    "test10pred_t = test_10pred.transpose()\n",
    "test_10preddf = pd.DataFrame(test_10pred)\n",
    "print(test_10preddf.head())\n",
    "unscaledoutput10 = pd.DataFrame(min_max_scaler.inverse_transform(test_10preddf))\n",
    "unscaledoutput10.columns = dataset.columns\n",
    "unscaledoutput10 = unscaledoutput10.astype(int)\n",
    "print(unscaledoutput10.head())\n",
    "unscaledoutput10.to_csv('predictions/wb10minpred.csv')\n",
    "test10Y_df = pd.DataFrame(test10Y)\n",
    "test10Y_unscaled = pd.DataFrame(min_max_scaler.inverse_transform(test10Y_df))\n",
    "test10Y_unscaled.columns=dataset.columns\n",
    "test10Y_unscaled = test10Y_unscaled.astype(int)\n",
    "test10Y_unscaled.to_csv('truths/wb10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "091f5ab9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AIkNNqZ2bKsE",
    "outputId": "9d25b8a0-cf5d-455d-e714-2e5afd973a2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "232/232 [==============================] - 9s 23ms/step - loss: 0.0606 - mse: 0.0105 - val_loss: 0.0517 - val_mse: 0.0078\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0480 - mse: 0.0066 - val_loss: 0.0505 - val_mse: 0.0073\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0463 - mse: 0.0060 - val_loss: 0.0504 - val_mse: 0.0073\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0452 - mse: 0.0058 - val_loss: 0.0492 - val_mse: 0.0068\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0449 - mse: 0.0057 - val_loss: 0.0490 - val_mse: 0.0068\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0447 - mse: 0.0056 - val_loss: 0.0481 - val_mse: 0.0065\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0446 - mse: 0.0056 - val_loss: 0.0473 - val_mse: 0.0064\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0442 - mse: 0.0055 - val_loss: 0.0501 - val_mse: 0.0072\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0438 - mse: 0.0054 - val_loss: 0.0477 - val_mse: 0.0064\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0445 - mse: 0.0056 - val_loss: 0.0471 - val_mse: 0.0062\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0440 - mse: 0.0055 - val_loss: 0.0475 - val_mse: 0.0064\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0438 - mse: 0.0054 - val_loss: 0.0480 - val_mse: 0.0064\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0438 - mse: 0.0054 - val_loss: 0.0460 - val_mse: 0.0060\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0433 - mse: 0.0053 - val_loss: 0.0475 - val_mse: 0.0061\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0431 - mse: 0.0052 - val_loss: 0.0453 - val_mse: 0.0055\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0429 - mse: 0.0052 - val_loss: 0.0460 - val_mse: 0.0059\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0430 - mse: 0.0051 - val_loss: 0.0458 - val_mse: 0.0056\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0422 - mse: 0.0050 - val_loss: 0.0463 - val_mse: 0.0057\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0433 - mse: 0.0052 - val_loss: 0.0482 - val_mse: 0.0063\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0429 - mse: 0.0051 - val_loss: 0.0462 - val_mse: 0.0058\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0428 - mse: 0.0051 - val_loss: 0.0454 - val_mse: 0.0057\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0427 - mse: 0.0051 - val_loss: 0.0475 - val_mse: 0.0062\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0425 - mse: 0.0050 - val_loss: 0.0456 - val_mse: 0.0056\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0424 - mse: 0.0050 - val_loss: 0.0453 - val_mse: 0.0055\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0424 - mse: 0.0050 - val_loss: 0.0449 - val_mse: 0.0055\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0424 - mse: 0.0050 - val_loss: 0.0457 - val_mse: 0.0058\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0426 - mse: 0.0050 - val_loss: 0.0453 - val_mse: 0.0056\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0422 - mse: 0.0049 - val_loss: 0.0448 - val_mse: 0.0056\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0422 - mse: 0.0049 - val_loss: 0.0461 - val_mse: 0.0060\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0419 - mse: 0.0049 - val_loss: 0.0463 - val_mse: 0.0057\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0420 - mse: 0.0049 - val_loss: 0.0425 - val_mse: 0.0050\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0425 - mse: 0.0050 - val_loss: 0.0454 - val_mse: 0.0055\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0421 - mse: 0.0049 - val_loss: 0.0456 - val_mse: 0.0058\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0420 - mse: 0.0049 - val_loss: 0.0456 - val_mse: 0.0056\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0419 - mse: 0.0048 - val_loss: 0.0469 - val_mse: 0.0059\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0418 - mse: 0.0048 - val_loss: 0.0449 - val_mse: 0.0055\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0414 - mse: 0.0048 - val_loss: 0.0445 - val_mse: 0.0055\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0047 - val_loss: 0.0429 - val_mse: 0.0051\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0415 - mse: 0.0048 - val_loss: 0.0447 - val_mse: 0.0055\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0413 - mse: 0.0047 - val_loss: 0.0454 - val_mse: 0.0056\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0412 - mse: 0.0047 - val_loss: 0.0455 - val_mse: 0.0058\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0414 - mse: 0.0047 - val_loss: 0.0458 - val_mse: 0.0057\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0046 - val_loss: 0.0455 - val_mse: 0.0056\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0412 - mse: 0.0047 - val_loss: 0.0434 - val_mse: 0.0052\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0411 - mse: 0.0046 - val_loss: 0.0446 - val_mse: 0.0054\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0046 - val_loss: 0.0448 - val_mse: 0.0055\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0412 - mse: 0.0047 - val_loss: 0.0442 - val_mse: 0.0054\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0408 - mse: 0.0046 - val_loss: 0.0448 - val_mse: 0.0056\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0046 - val_loss: 0.0445 - val_mse: 0.0054\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0046 - val_loss: 0.0473 - val_mse: 0.0061\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0412 - mse: 0.0047 - val_loss: 0.0445 - val_mse: 0.0054\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0409 - mse: 0.0046 - val_loss: 0.0446 - val_mse: 0.0054\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0046 - val_loss: 0.0437 - val_mse: 0.0053\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0407 - mse: 0.0046 - val_loss: 0.0440 - val_mse: 0.0053\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0045 - val_loss: 0.0442 - val_mse: 0.0054\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0407 - mse: 0.0045 - val_loss: 0.0437 - val_mse: 0.0052\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0045 - val_loss: 0.0447 - val_mse: 0.0055\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0414 - mse: 0.0048 - val_loss: 0.0449 - val_mse: 0.0055\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0408 - mse: 0.0046 - val_loss: 0.0459 - val_mse: 0.0057\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0410 - mse: 0.0046 - val_loss: 0.0449 - val_mse: 0.0055\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0045 - val_loss: 0.0446 - val_mse: 0.0055\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0045 - val_loss: 0.0446 - val_mse: 0.0055\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0405 - mse: 0.0045 - val_loss: 0.0447 - val_mse: 0.0056\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0404 - mse: 0.0045 - val_loss: 0.0439 - val_mse: 0.0054\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0404 - mse: 0.0045 - val_loss: 0.0448 - val_mse: 0.0056\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0045 - val_loss: 0.0454 - val_mse: 0.0057\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0405 - mse: 0.0045 - val_loss: 0.0439 - val_mse: 0.0054\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0405 - mse: 0.0045 - val_loss: 0.0435 - val_mse: 0.0054\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0404 - mse: 0.0045 - val_loss: 0.0429 - val_mse: 0.0051\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0405 - mse: 0.0045 - val_loss: 0.0439 - val_mse: 0.0055\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0045 - val_loss: 0.0450 - val_mse: 0.0054\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0403 - mse: 0.0045 - val_loss: 0.0427 - val_mse: 0.0051\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0406 - mse: 0.0045 - val_loss: 0.0442 - val_mse: 0.0055\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0402 - mse: 0.0044 - val_loss: 0.0445 - val_mse: 0.0055\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0400 - mse: 0.0044 - val_loss: 0.0427 - val_mse: 0.0052\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0405 - mse: 0.0045 - val_loss: 0.0449 - val_mse: 0.0055\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0400 - mse: 0.0044 - val_loss: 0.0440 - val_mse: 0.0053\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0404 - mse: 0.0044 - val_loss: 0.0434 - val_mse: 0.0052\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0402 - mse: 0.0044 - val_loss: 0.0423 - val_mse: 0.0050\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0400 - mse: 0.0044 - val_loss: 0.0491 - val_mse: 0.0066\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0400 - mse: 0.0044 - val_loss: 0.0419 - val_mse: 0.0050\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0400 - mse: 0.0044 - val_loss: 0.0457 - val_mse: 0.0059\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0396 - mse: 0.0043 - val_loss: 0.0442 - val_mse: 0.0054\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0395 - mse: 0.0043 - val_loss: 0.0401 - val_mse: 0.0046\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0393 - mse: 0.0042 - val_loss: 0.0408 - val_mse: 0.0048\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0394 - mse: 0.0042 - val_loss: 0.0412 - val_mse: 0.0050\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0391 - mse: 0.0042 - val_loss: 0.0418 - val_mse: 0.0049\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0389 - mse: 0.0041 - val_loss: 0.0411 - val_mse: 0.0047\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0391 - mse: 0.0042 - val_loss: 0.0404 - val_mse: 0.0047\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0388 - mse: 0.0041 - val_loss: 0.0389 - val_mse: 0.0044\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0393 - mse: 0.0043 - val_loss: 0.0395 - val_mse: 0.0046\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0391 - mse: 0.0042 - val_loss: 0.0404 - val_mse: 0.0047\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0387 - mse: 0.0041 - val_loss: 0.0406 - val_mse: 0.0047\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0385 - mse: 0.0041 - val_loss: 0.0391 - val_mse: 0.0043\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0389 - mse: 0.0041 - val_loss: 0.0405 - val_mse: 0.0046\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0393 - mse: 0.0042 - val_loss: 0.0379 - val_mse: 0.0043\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0385 - mse: 0.0040 - val_loss: 0.0408 - val_mse: 0.0048\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0387 - mse: 0.0041 - val_loss: 0.0401 - val_mse: 0.0047\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0382 - mse: 0.0040 - val_loss: 0.0389 - val_mse: 0.0044\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0386 - mse: 0.0040 - val_loss: 0.0380 - val_mse: 0.0042\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0386 - mse: 0.0041 - val_loss: 0.0394 - val_mse: 0.0044\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0382 - mse: 0.0040 - val_loss: 0.0380 - val_mse: 0.0043\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0384 - mse: 0.0040 - val_loss: 0.0399 - val_mse: 0.0046\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0381 - mse: 0.0039 - val_loss: 0.0392 - val_mse: 0.0044\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0381 - mse: 0.0040 - val_loss: 0.0388 - val_mse: 0.0044\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0382 - mse: 0.0040 - val_loss: 0.0379 - val_mse: 0.0043\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0380 - mse: 0.0039 - val_loss: 0.0377 - val_mse: 0.0043\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0380 - mse: 0.0039 - val_loss: 0.0404 - val_mse: 0.0046\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0382 - mse: 0.0040 - val_loss: 0.0392 - val_mse: 0.0044\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0382 - mse: 0.0040 - val_loss: 0.0396 - val_mse: 0.0046\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0380 - mse: 0.0039 - val_loss: 0.0389 - val_mse: 0.0044\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0381 - mse: 0.0040 - val_loss: 0.0379 - val_mse: 0.0043\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0382 - mse: 0.0040 - val_loss: 0.0442 - val_mse: 0.0054\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0380 - mse: 0.0039 - val_loss: 0.0374 - val_mse: 0.0041\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0381 - mse: 0.0040 - val_loss: 0.0385 - val_mse: 0.0044\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0380 - mse: 0.0039 - val_loss: 0.0375 - val_mse: 0.0042\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0378 - mse: 0.0039 - val_loss: 0.0423 - val_mse: 0.0049\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0381 - mse: 0.0040 - val_loss: 0.0373 - val_mse: 0.0041\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0376 - mse: 0.0038 - val_loss: 0.0376 - val_mse: 0.0042\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0379 - mse: 0.0039 - val_loss: 0.0397 - val_mse: 0.0044\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0378 - mse: 0.0039 - val_loss: 0.0370 - val_mse: 0.0041\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0382 - mse: 0.0040 - val_loss: 0.0391 - val_mse: 0.0044\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0379 - mse: 0.0039 - val_loss: 0.0377 - val_mse: 0.0042\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0378 - mse: 0.0039 - val_loss: 0.0390 - val_mse: 0.0044\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0379 - mse: 0.0039 - val_loss: 0.0401 - val_mse: 0.0045\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0380 - mse: 0.0039 - val_loss: 0.0378 - val_mse: 0.0041\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0381 - mse: 0.0040 - val_loss: 0.0390 - val_mse: 0.0044\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0379 - mse: 0.0039 - val_loss: 0.0384 - val_mse: 0.0044\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0384 - mse: 0.0040 - val_loss: 0.0375 - val_mse: 0.0042\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0379 - mse: 0.0039 - val_loss: 0.0385 - val_mse: 0.0043\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0377 - mse: 0.0039 - val_loss: 0.0380 - val_mse: 0.0042\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0378 - mse: 0.0039 - val_loss: 0.0400 - val_mse: 0.0046\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0376 - mse: 0.0039 - val_loss: 0.0376 - val_mse: 0.0041\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0376 - mse: 0.0039 - val_loss: 0.0368 - val_mse: 0.0040\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0381 - mse: 0.0040 - val_loss: 0.0371 - val_mse: 0.0040\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0379 - mse: 0.0039 - val_loss: 0.0389 - val_mse: 0.0043\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0377 - mse: 0.0039 - val_loss: 0.0379 - val_mse: 0.0042\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0377 - mse: 0.0039 - val_loss: 0.0386 - val_mse: 0.0043\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0376 - mse: 0.0039 - val_loss: 0.0398 - val_mse: 0.0045\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0377 - mse: 0.0039 - val_loss: 0.0381 - val_mse: 0.0042\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0374 - mse: 0.0038 - val_loss: 0.0392 - val_mse: 0.0043\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0376 - mse: 0.0038 - val_loss: 0.0381 - val_mse: 0.0042\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0377 - mse: 0.0039 - val_loss: 0.0379 - val_mse: 0.0043\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0378 - mse: 0.0039 - val_loss: 0.0373 - val_mse: 0.0041\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0378 - mse: 0.0039 - val_loss: 0.0407 - val_mse: 0.0047\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0379 - mse: 0.0039 - val_loss: 0.0382 - val_mse: 0.0042\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0379 - mse: 0.0039 - val_loss: 0.0404 - val_mse: 0.0048\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0383 - mse: 0.0040 - val_loss: 0.0372 - val_mse: 0.0041\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0374 - mse: 0.0038 - val_loss: 0.0374 - val_mse: 0.0042\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0383 - mse: 0.0040 - val_loss: 0.0384 - val_mse: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/WBmodels/wb15/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/WBmodels/wb15/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2  ...         5         6         7\n",
      "0  0.007889  0.518986  0.014674  ...  0.438146  0.016831  0.628476\n",
      "1  0.008421  0.518859  0.015667  ...  0.437773  0.018004  0.628259\n",
      "2  0.008831  0.518600  0.016440  ...  0.437426  0.018833  0.628174\n",
      "3  0.008769  0.518521  0.016334  ...  0.437375  0.018660  0.628129\n",
      "4  0.008752  0.518511  0.016303  ...  0.437356  0.018624  0.628051\n",
      "\n",
      "[5 rows x 8 columns]\n",
      "   063Volume  063Speed  051Volume  ...  031Speed  003Volume  003Speed\n",
      "0          0        98          2  ...        96          2        92\n",
      "1          0        98          2  ...        96          2        92\n",
      "2          0        98          2  ...        96          2        92\n",
      "3          0        98          2  ...        96          2        92\n",
      "4          0        98          2  ...        96          2        92\n",
      "\n",
      "[5 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10 #length of data used for the prediction, currently using the last 10 mins of data\n",
    "pre_len = 15 # distance of prediction, currently predicting speeds and volumes 30 mins from now\n",
    "\n",
    "train15X, train15Y,val15X,val15Y, test15X, test15Y = sequence_data_preparation(\n",
    "    seq_len, pre_len, train_data_t, val_data_t,test_data_t)\n",
    "\n",
    "optimizer2=keras.optimizers.Adam(learning_rate=.01)\n",
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=corrmatrix,\n",
    "    gc_layer_sizes=[16, 10],\n",
    "    gc_activations=[\"relu\", \"relu\"],\n",
    "    lstm_layer_sizes=[200, 200],\n",
    "    lstm_activations=[\"tanh\", \"tanh\"],\n",
    "    )\n",
    "x_input, x_output = gcn_lstm.in_out_tensors()\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "model.compile(optimizer=optimizer2, loss=\"mae\", metrics=[\"mse\"])\n",
    "history = model.fit(\n",
    "    train15X,\n",
    "    train15Y,\n",
    "    epochs=150,\n",
    "    batch_size=200,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(val15X, val15Y),\n",
    ")\n",
    "loss15 = history.history['val_loss'][149]\n",
    "tloss15 = history.history['loss'][149]\n",
    "model.save(\"WBmodels/wb15\")\n",
    "train_15pred = model.predict(train15X)\n",
    "test_15pred= model.predict(test15X)\n",
    "testloss15=mae(test15Y,test_15pred).numpy()\n",
    "\n",
    "test15pred_t = test_15pred.transpose()\n",
    "test_15preddf = pd.DataFrame(test_15pred)\n",
    "print(test_15preddf.head())\n",
    "unscaledoutput15 = pd.DataFrame(min_max_scaler.inverse_transform(test_15preddf))\n",
    "unscaledoutput15.columns = dataset.columns\n",
    "unscaledoutput15 = unscaledoutput15.astype(int)\n",
    "print(unscaledoutput15.head())\n",
    "unscaledoutput15.to_csv('predictions/wb15minpred.csv')\n",
    "test15Y_df = pd.DataFrame(test15Y)\n",
    "test15Y_unscaled = pd.DataFrame(min_max_scaler.inverse_transform(test15Y_df))\n",
    "test15Y_unscaled.columns=dataset.columns\n",
    "test15Y_unscaled = test15Y_unscaled.astype(int)\n",
    "test15Y_unscaled.to_csv('truths/wb15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0c0a2ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDLZ4jDUbhEW",
    "outputId": "ec158b26-7f20-424a-c30c-78d231fdf74d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "232/232 [==============================] - 9s 24ms/step - loss: 0.0644 - mse: 0.0119 - val_loss: 0.0565 - val_mse: 0.0096\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 4s 19ms/step - loss: 0.0545 - mse: 0.0090 - val_loss: 0.0573 - val_mse: 0.0101\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0536 - mse: 0.0087 - val_loss: 0.0535 - val_mse: 0.0088\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0531 - mse: 0.0085 - val_loss: 0.0551 - val_mse: 0.0093\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0528 - mse: 0.0085 - val_loss: 0.0550 - val_mse: 0.0088\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0525 - mse: 0.0083 - val_loss: 0.0544 - val_mse: 0.0087\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0523 - mse: 0.0082 - val_loss: 0.0527 - val_mse: 0.0084\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0521 - mse: 0.0081 - val_loss: 0.0536 - val_mse: 0.0083\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0520 - mse: 0.0081 - val_loss: 0.0538 - val_mse: 0.0081\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0518 - mse: 0.0080 - val_loss: 0.0521 - val_mse: 0.0081\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0515 - mse: 0.0079 - val_loss: 0.0509 - val_mse: 0.0078\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0518 - mse: 0.0080 - val_loss: 0.0520 - val_mse: 0.0082\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0519 - mse: 0.0081 - val_loss: 0.0524 - val_mse: 0.0088\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0518 - mse: 0.0081 - val_loss: 0.0535 - val_mse: 0.0086\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0512 - mse: 0.0077 - val_loss: 0.0523 - val_mse: 0.0084\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0516 - mse: 0.0080 - val_loss: 0.0532 - val_mse: 0.0086\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0512 - mse: 0.0078 - val_loss: 0.0508 - val_mse: 0.0077\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0511 - mse: 0.0077 - val_loss: 0.0501 - val_mse: 0.0077\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0506 - mse: 0.0075 - val_loss: 0.0496 - val_mse: 0.0071\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0510 - mse: 0.0077 - val_loss: 0.0521 - val_mse: 0.0083\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0507 - mse: 0.0077 - val_loss: 0.0504 - val_mse: 0.0075\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0504 - mse: 0.0075 - val_loss: 0.0511 - val_mse: 0.0079\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0503 - mse: 0.0075 - val_loss: 0.0509 - val_mse: 0.0077\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0504 - mse: 0.0075 - val_loss: 0.0498 - val_mse: 0.0074\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0502 - mse: 0.0075 - val_loss: 0.0522 - val_mse: 0.0080\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0501 - mse: 0.0074 - val_loss: 0.0492 - val_mse: 0.0072\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0501 - mse: 0.0074 - val_loss: 0.0505 - val_mse: 0.0078\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0497 - mse: 0.0073 - val_loss: 0.0512 - val_mse: 0.0081\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0494 - mse: 0.0071 - val_loss: 0.0507 - val_mse: 0.0081\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0495 - mse: 0.0071 - val_loss: 0.0507 - val_mse: 0.0071\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0497 - mse: 0.0073 - val_loss: 0.0489 - val_mse: 0.0075\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0503 - mse: 0.0076 - val_loss: 0.0504 - val_mse: 0.0073\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0494 - mse: 0.0072 - val_loss: 0.0496 - val_mse: 0.0068\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0486 - mse: 0.0068 - val_loss: 0.0516 - val_mse: 0.0083\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0496 - mse: 0.0073 - val_loss: 0.0498 - val_mse: 0.0071\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0487 - mse: 0.0069 - val_loss: 0.0517 - val_mse: 0.0083\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0488 - mse: 0.0069 - val_loss: 0.0495 - val_mse: 0.0072\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0495 - mse: 0.0073 - val_loss: 0.0488 - val_mse: 0.0072\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0492 - mse: 0.0071 - val_loss: 0.0476 - val_mse: 0.0065\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0487 - mse: 0.0069 - val_loss: 0.0493 - val_mse: 0.0076\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0486 - mse: 0.0068 - val_loss: 0.0489 - val_mse: 0.0068\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0480 - mse: 0.0067 - val_loss: 0.0502 - val_mse: 0.0074\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0488 - mse: 0.0070 - val_loss: 0.0483 - val_mse: 0.0068\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0488 - mse: 0.0071 - val_loss: 0.0496 - val_mse: 0.0078\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0493 - mse: 0.0072 - val_loss: 0.0504 - val_mse: 0.0079\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0489 - mse: 0.0071 - val_loss: 0.0513 - val_mse: 0.0071\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0486 - mse: 0.0069 - val_loss: 0.0487 - val_mse: 0.0067\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0481 - mse: 0.0068 - val_loss: 0.0486 - val_mse: 0.0068\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0473 - mse: 0.0064 - val_loss: 0.0486 - val_mse: 0.0068\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0475 - mse: 0.0065 - val_loss: 0.0497 - val_mse: 0.0068\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0476 - mse: 0.0066 - val_loss: 0.0460 - val_mse: 0.0062\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0474 - mse: 0.0065 - val_loss: 0.0513 - val_mse: 0.0085\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0478 - mse: 0.0066 - val_loss: 0.0480 - val_mse: 0.0066\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0480 - mse: 0.0067 - val_loss: 0.0491 - val_mse: 0.0067\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0475 - mse: 0.0065 - val_loss: 0.0502 - val_mse: 0.0080\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0473 - mse: 0.0065 - val_loss: 0.0467 - val_mse: 0.0062\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0472 - mse: 0.0064 - val_loss: 0.0474 - val_mse: 0.0065\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0478 - mse: 0.0067 - val_loss: 0.0500 - val_mse: 0.0079\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0474 - mse: 0.0065 - val_loss: 0.0507 - val_mse: 0.0076\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0478 - mse: 0.0067 - val_loss: 0.0495 - val_mse: 0.0077\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0476 - mse: 0.0066 - val_loss: 0.0504 - val_mse: 0.0082\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0479 - mse: 0.0067 - val_loss: 0.0476 - val_mse: 0.0066\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0479 - mse: 0.0067 - val_loss: 0.0471 - val_mse: 0.0066\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0468 - mse: 0.0063 - val_loss: 0.0483 - val_mse: 0.0071\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0475 - mse: 0.0066 - val_loss: 0.0468 - val_mse: 0.0064\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0471 - mse: 0.0065 - val_loss: 0.0485 - val_mse: 0.0070\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0488 - mse: 0.0071 - val_loss: 0.0482 - val_mse: 0.0065\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0477 - mse: 0.0067 - val_loss: 0.0496 - val_mse: 0.0068\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0475 - mse: 0.0066 - val_loss: 0.0471 - val_mse: 0.0063\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0468 - mse: 0.0063 - val_loss: 0.0458 - val_mse: 0.0061\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0472 - mse: 0.0065 - val_loss: 0.0454 - val_mse: 0.0061\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0468 - mse: 0.0064 - val_loss: 0.0528 - val_mse: 0.0086\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0504 - mse: 0.0079 - val_loss: 0.0495 - val_mse: 0.0080\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0492 - mse: 0.0074 - val_loss: 0.0514 - val_mse: 0.0078\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0485 - mse: 0.0069 - val_loss: 0.0511 - val_mse: 0.0081\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0489 - mse: 0.0071 - val_loss: 0.0482 - val_mse: 0.0068\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0477 - mse: 0.0066 - val_loss: 0.0492 - val_mse: 0.0069\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0474 - mse: 0.0065 - val_loss: 0.0490 - val_mse: 0.0073\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0477 - mse: 0.0067 - val_loss: 0.0497 - val_mse: 0.0070\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0477 - mse: 0.0066 - val_loss: 0.0516 - val_mse: 0.0081\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0471 - mse: 0.0064 - val_loss: 0.0463 - val_mse: 0.0063\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0468 - mse: 0.0063 - val_loss: 0.0498 - val_mse: 0.0067\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0468 - mse: 0.0064 - val_loss: 0.0472 - val_mse: 0.0066\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0463 - mse: 0.0062 - val_loss: 0.0465 - val_mse: 0.0064\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0476 - mse: 0.0066 - val_loss: 0.0468 - val_mse: 0.0064\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0492 - mse: 0.0074 - val_loss: 0.0514 - val_mse: 0.0082\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0497 - mse: 0.0075 - val_loss: 0.0501 - val_mse: 0.0077\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0489 - mse: 0.0071 - val_loss: 0.0494 - val_mse: 0.0070\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0480 - mse: 0.0067 - val_loss: 0.0472 - val_mse: 0.0067\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0471 - mse: 0.0064 - val_loss: 0.0460 - val_mse: 0.0062\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0484 - mse: 0.0070 - val_loss: 0.0509 - val_mse: 0.0083\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0476 - mse: 0.0066 - val_loss: 0.0497 - val_mse: 0.0076\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0487 - mse: 0.0071 - val_loss: 0.0468 - val_mse: 0.0063\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0469 - mse: 0.0063 - val_loss: 0.0482 - val_mse: 0.0069\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0469 - mse: 0.0064 - val_loss: 0.0500 - val_mse: 0.0069\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0483 - mse: 0.0070 - val_loss: 0.0488 - val_mse: 0.0075\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0476 - mse: 0.0066 - val_loss: 0.0473 - val_mse: 0.0064\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0475 - mse: 0.0066 - val_loss: 0.0501 - val_mse: 0.0081\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0467 - mse: 0.0063 - val_loss: 0.0497 - val_mse: 0.0067\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0471 - mse: 0.0064 - val_loss: 0.0496 - val_mse: 0.0068\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0467 - mse: 0.0063 - val_loss: 0.0491 - val_mse: 0.0076\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0463 - mse: 0.0062 - val_loss: 0.0448 - val_mse: 0.0059\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0464 - mse: 0.0062 - val_loss: 0.0461 - val_mse: 0.0062\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0456 - mse: 0.0060 - val_loss: 0.0469 - val_mse: 0.0066\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0462 - mse: 0.0062 - val_loss: 0.0457 - val_mse: 0.0062\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0468 - mse: 0.0064 - val_loss: 0.0498 - val_mse: 0.0068\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0468 - mse: 0.0064 - val_loss: 0.0462 - val_mse: 0.0063\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0457 - mse: 0.0060 - val_loss: 0.0494 - val_mse: 0.0073\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0462 - mse: 0.0062 - val_loss: 0.0460 - val_mse: 0.0062\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0455 - mse: 0.0060 - val_loss: 0.0464 - val_mse: 0.0064\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0462 - mse: 0.0062 - val_loss: 0.0514 - val_mse: 0.0076\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0462 - mse: 0.0062 - val_loss: 0.0463 - val_mse: 0.0063\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0473 - mse: 0.0066 - val_loss: 0.0463 - val_mse: 0.0063\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0465 - mse: 0.0063 - val_loss: 0.0499 - val_mse: 0.0068\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0454 - mse: 0.0059 - val_loss: 0.0496 - val_mse: 0.0073\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0457 - mse: 0.0060 - val_loss: 0.0446 - val_mse: 0.0059\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0459 - mse: 0.0061 - val_loss: 0.0476 - val_mse: 0.0065\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0459 - mse: 0.0061 - val_loss: 0.0468 - val_mse: 0.0063\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0450 - mse: 0.0059 - val_loss: 0.0461 - val_mse: 0.0062\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0452 - mse: 0.0059 - val_loss: 0.0496 - val_mse: 0.0075\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0458 - mse: 0.0061 - val_loss: 0.0436 - val_mse: 0.0057\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0445 - mse: 0.0057 - val_loss: 0.0490 - val_mse: 0.0078\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0446 - mse: 0.0057 - val_loss: 0.0439 - val_mse: 0.0058\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0445 - mse: 0.0057 - val_loss: 0.0489 - val_mse: 0.0066\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0448 - mse: 0.0058 - val_loss: 0.0438 - val_mse: 0.0058\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0454 - mse: 0.0060 - val_loss: 0.0435 - val_mse: 0.0057\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0446 - mse: 0.0058 - val_loss: 0.0438 - val_mse: 0.0057\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0454 - mse: 0.0061 - val_loss: 0.0468 - val_mse: 0.0073\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0447 - mse: 0.0058 - val_loss: 0.0451 - val_mse: 0.0066\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0444 - mse: 0.0057 - val_loss: 0.0467 - val_mse: 0.0069\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0453 - mse: 0.0060 - val_loss: 0.0434 - val_mse: 0.0057\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0451 - mse: 0.0059 - val_loss: 0.0465 - val_mse: 0.0071\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0447 - mse: 0.0058 - val_loss: 0.0424 - val_mse: 0.0053\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0442 - mse: 0.0057 - val_loss: 0.0424 - val_mse: 0.0053\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0440 - mse: 0.0056 - val_loss: 0.0445 - val_mse: 0.0060\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0439 - mse: 0.0056 - val_loss: 0.0471 - val_mse: 0.0062\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0442 - mse: 0.0057 - val_loss: 0.0430 - val_mse: 0.0054\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0439 - mse: 0.0056 - val_loss: 0.0430 - val_mse: 0.0056\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0445 - mse: 0.0058 - val_loss: 0.0419 - val_mse: 0.0053\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0446 - mse: 0.0058 - val_loss: 0.0436 - val_mse: 0.0059\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0445 - mse: 0.0058 - val_loss: 0.0465 - val_mse: 0.0070\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0442 - mse: 0.0056 - val_loss: 0.0425 - val_mse: 0.0054\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0448 - mse: 0.0058 - val_loss: 0.0439 - val_mse: 0.0059\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0438 - mse: 0.0055 - val_loss: 0.0418 - val_mse: 0.0053\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0438 - mse: 0.0055 - val_loss: 0.0432 - val_mse: 0.0056\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0443 - mse: 0.0057 - val_loss: 0.0434 - val_mse: 0.0059\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0441 - mse: 0.0056 - val_loss: 0.0418 - val_mse: 0.0053\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0433 - mse: 0.0054 - val_loss: 0.0453 - val_mse: 0.0066\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0438 - mse: 0.0055 - val_loss: 0.0469 - val_mse: 0.0072\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0467 - mse: 0.0065 - val_loss: 0.0458 - val_mse: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/WBmodels/wb45/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/WBmodels/wb45/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2  ...         5         6         7\n",
      "0  0.009089  0.521436  0.017420  ...  0.446460  0.019314  0.638762\n",
      "1  0.009476  0.521307  0.018133  ...  0.446196  0.020233  0.638605\n",
      "2  0.009207  0.521351  0.017564  ...  0.446487  0.019298  0.638925\n",
      "3  0.008908  0.521428  0.016939  ...  0.446804  0.018291  0.639286\n",
      "4  0.008996  0.521383  0.017057  ...  0.446730  0.018323  0.639389\n",
      "\n",
      "[5 rows x 8 columns]\n",
      "   063Volume  063Speed  051Volume  ...  031Speed  003Volume  003Speed\n",
      "0          0        99          2  ...        98          3        93\n",
      "1          1        99          2  ...        98          3        93\n",
      "2          1        99          2  ...        98          3        93\n",
      "3          0        99          2  ...        98          2        93\n",
      "4          0        99          2  ...        98          2        93\n",
      "\n",
      "[5 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10 #length of data used for the prediction, currently using the last 10 mins of data\n",
    "pre_len = 45 # distance of prediction, currently predicting speeds and volumes 30 mins from now\n",
    "\n",
    "train45X, train45Y,val45X,val45Y, test45X, test45Y = sequence_data_preparation(\n",
    "    seq_len, pre_len, train_data_t, val_data_t,test_data_t)\n",
    "\n",
    "optimizer2=keras.optimizers.Adam(learning_rate=.01)\n",
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=corrmatrix,\n",
    "    gc_layer_sizes=[16, 10],\n",
    "    gc_activations=[\"relu\", \"relu\"],\n",
    "    lstm_layer_sizes=[200, 200],\n",
    "    lstm_activations=[\"tanh\", \"tanh\"],\n",
    "    )\n",
    "x_input, x_output = gcn_lstm.in_out_tensors()\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "model.compile(optimizer=optimizer2, loss=\"mae\", metrics=[\"mse\"])\n",
    "history = model.fit(\n",
    "    train45X,\n",
    "    train45Y,\n",
    "    epochs=150,\n",
    "    batch_size=200,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(val45X, val45Y),\n",
    ")\n",
    "loss45 = history.history['val_loss'][149]\n",
    "tloss45 = history.history['loss'][149]\n",
    "model.save(\"WBmodels/wb45\")\n",
    "train_45pred = model.predict(train45X)\n",
    "test_45pred= model.predict(test45X)\n",
    "testloss45=mae(test45Y,test_45pred).numpy()\n",
    "\n",
    "test45pred_t = test_45pred.transpose()\n",
    "test_45preddf = pd.DataFrame(test_45pred)\n",
    "print(test_45preddf.head())\n",
    "unscaledoutput45 = pd.DataFrame(min_max_scaler.inverse_transform(test_45preddf))\n",
    "unscaledoutput45.columns = dataset.columns\n",
    "unscaledoutput45 = unscaledoutput45.astype(int)\n",
    "print(unscaledoutput45.head())\n",
    "unscaledoutput45.to_csv('predictions/wb45minpred.csv')\n",
    "test45Y_df = pd.DataFrame(test45Y)\n",
    "test45Y_unscaled = pd.DataFrame(min_max_scaler.inverse_transform(test45Y_df))\n",
    "test45Y_unscaled.columns=dataset.columns\n",
    "test45Y_unscaled = test45Y_unscaled.astype(int)\n",
    "test45Y_unscaled.to_csv('truths/wb45.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d8b0e12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHQhNLV6bwn4",
    "outputId": "c95e74a9-ec7b-4a55-b617-ade300d4fe10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: ExperimentalWarning: GCN_LSTM is experimental: Lack of unit tests and code refinement (see: https://github.com/stellargraph/stellargraph/issues/1132, https://github.com/stellargraph/stellargraph/issues/1526, https://github.com/stellargraph/stellargraph/issues/1564). It may be difficult to use and may have major changes at any time.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "232/232 [==============================] - 9s 23ms/step - loss: 0.0701 - mse: 0.0146 - val_loss: 0.0622 - val_mse: 0.0125\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 4s 19ms/step - loss: 0.0595 - mse: 0.0114 - val_loss: 0.0612 - val_mse: 0.0109\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0584 - mse: 0.0110 - val_loss: 0.0588 - val_mse: 0.0113\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0582 - mse: 0.0109 - val_loss: 0.0609 - val_mse: 0.0120\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0575 - mse: 0.0106 - val_loss: 0.0626 - val_mse: 0.0125\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0574 - mse: 0.0105 - val_loss: 0.0567 - val_mse: 0.0100\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0572 - mse: 0.0105 - val_loss: 0.0581 - val_mse: 0.0108\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0571 - mse: 0.0104 - val_loss: 0.0587 - val_mse: 0.0108\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0568 - mse: 0.0103 - val_loss: 0.0570 - val_mse: 0.0098\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0568 - mse: 0.0103 - val_loss: 0.0572 - val_mse: 0.0103\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0570 - mse: 0.0103 - val_loss: 0.0585 - val_mse: 0.0107\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0567 - mse: 0.0103 - val_loss: 0.0567 - val_mse: 0.0102\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0562 - mse: 0.0100 - val_loss: 0.0614 - val_mse: 0.0123\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0568 - mse: 0.0104 - val_loss: 0.0569 - val_mse: 0.0102\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0562 - mse: 0.0101 - val_loss: 0.0576 - val_mse: 0.0100\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0558 - mse: 0.0099 - val_loss: 0.0559 - val_mse: 0.0093\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0560 - mse: 0.0099 - val_loss: 0.0572 - val_mse: 0.0103\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0559 - mse: 0.0098 - val_loss: 0.0565 - val_mse: 0.0102\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0556 - mse: 0.0097 - val_loss: 0.0560 - val_mse: 0.0098\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0576 - mse: 0.0107 - val_loss: 0.0568 - val_mse: 0.0100\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0565 - mse: 0.0101 - val_loss: 0.0581 - val_mse: 0.0106\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0566 - mse: 0.0102 - val_loss: 0.0564 - val_mse: 0.0102\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0558 - mse: 0.0099 - val_loss: 0.0554 - val_mse: 0.0095\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0558 - mse: 0.0099 - val_loss: 0.0557 - val_mse: 0.0097\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0561 - mse: 0.0099 - val_loss: 0.0577 - val_mse: 0.0108\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0562 - mse: 0.0100 - val_loss: 0.0568 - val_mse: 0.0092\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0565 - mse: 0.0102 - val_loss: 0.0579 - val_mse: 0.0109\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0564 - mse: 0.0102 - val_loss: 0.0568 - val_mse: 0.0102\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0563 - mse: 0.0103 - val_loss: 0.0558 - val_mse: 0.0099\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0556 - mse: 0.0099 - val_loss: 0.0557 - val_mse: 0.0094\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0555 - mse: 0.0097 - val_loss: 0.0540 - val_mse: 0.0092\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0555 - mse: 0.0098 - val_loss: 0.0562 - val_mse: 0.0096\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0553 - mse: 0.0097 - val_loss: 0.0558 - val_mse: 0.0098\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0550 - mse: 0.0095 - val_loss: 0.0533 - val_mse: 0.0089\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0564 - mse: 0.0102 - val_loss: 0.0558 - val_mse: 0.0097\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0565 - mse: 0.0103 - val_loss: 0.0566 - val_mse: 0.0104\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0555 - mse: 0.0099 - val_loss: 0.0601 - val_mse: 0.0097\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0550 - mse: 0.0095 - val_loss: 0.0572 - val_mse: 0.0099\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0548 - mse: 0.0093 - val_loss: 0.0563 - val_mse: 0.0103\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0552 - mse: 0.0095 - val_loss: 0.0551 - val_mse: 0.0100\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0550 - mse: 0.0097 - val_loss: 0.0548 - val_mse: 0.0088\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0556 - mse: 0.0099 - val_loss: 0.0561 - val_mse: 0.0105\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0549 - mse: 0.0096 - val_loss: 0.0546 - val_mse: 0.0100\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0557 - mse: 0.0098 - val_loss: 0.0550 - val_mse: 0.0096\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0553 - mse: 0.0097 - val_loss: 0.0580 - val_mse: 0.0109\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0551 - mse: 0.0097 - val_loss: 0.0568 - val_mse: 0.0086\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0551 - mse: 0.0096 - val_loss: 0.0551 - val_mse: 0.0097\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0543 - mse: 0.0092 - val_loss: 0.0540 - val_mse: 0.0095\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0554 - mse: 0.0098 - val_loss: 0.0550 - val_mse: 0.0096\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0562 - mse: 0.0101 - val_loss: 0.0589 - val_mse: 0.0107\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0570 - mse: 0.0104 - val_loss: 0.0578 - val_mse: 0.0106\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0568 - mse: 0.0103 - val_loss: 0.0569 - val_mse: 0.0105\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0563 - mse: 0.0101 - val_loss: 0.0564 - val_mse: 0.0100\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0557 - mse: 0.0098 - val_loss: 0.0553 - val_mse: 0.0096\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0556 - mse: 0.0098 - val_loss: 0.0559 - val_mse: 0.0103\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0554 - mse: 0.0097 - val_loss: 0.0613 - val_mse: 0.0100\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0554 - mse: 0.0095 - val_loss: 0.0564 - val_mse: 0.0095\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0553 - mse: 0.0097 - val_loss: 0.0542 - val_mse: 0.0092\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0552 - mse: 0.0096 - val_loss: 0.0565 - val_mse: 0.0100\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0549 - mse: 0.0095 - val_loss: 0.0526 - val_mse: 0.0081\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0559 - mse: 0.0099 - val_loss: 0.0569 - val_mse: 0.0104\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0549 - mse: 0.0095 - val_loss: 0.0559 - val_mse: 0.0099\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0554 - mse: 0.0097 - val_loss: 0.0608 - val_mse: 0.0117\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0568 - mse: 0.0104 - val_loss: 0.0583 - val_mse: 0.0109\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0564 - mse: 0.0103 - val_loss: 0.0570 - val_mse: 0.0107\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0562 - mse: 0.0101 - val_loss: 0.0568 - val_mse: 0.0103\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0557 - mse: 0.0100 - val_loss: 0.0556 - val_mse: 0.0101\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0554 - mse: 0.0097 - val_loss: 0.0571 - val_mse: 0.0093\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0554 - mse: 0.0097 - val_loss: 0.0545 - val_mse: 0.0095\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0553 - mse: 0.0096 - val_loss: 0.0538 - val_mse: 0.0093\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0550 - mse: 0.0093 - val_loss: 0.0539 - val_mse: 0.0096\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0558 - mse: 0.0099 - val_loss: 0.0550 - val_mse: 0.0099\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0549 - mse: 0.0095 - val_loss: 0.0560 - val_mse: 0.0100\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0570 - mse: 0.0103 - val_loss: 0.0580 - val_mse: 0.0108\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0563 - mse: 0.0102 - val_loss: 0.0579 - val_mse: 0.0105\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0562 - mse: 0.0101 - val_loss: 0.0562 - val_mse: 0.0101\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0560 - mse: 0.0101 - val_loss: 0.0563 - val_mse: 0.0103\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0561 - mse: 0.0102 - val_loss: 0.0571 - val_mse: 0.0104\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0560 - mse: 0.0101 - val_loss: 0.0577 - val_mse: 0.0108\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0559 - mse: 0.0100 - val_loss: 0.0567 - val_mse: 0.0105\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0560 - mse: 0.0101 - val_loss: 0.0579 - val_mse: 0.0104\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0557 - mse: 0.0100 - val_loss: 0.0558 - val_mse: 0.0101\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0561 - mse: 0.0100 - val_loss: 0.0555 - val_mse: 0.0099\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0558 - mse: 0.0100 - val_loss: 0.0552 - val_mse: 0.0099\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0553 - mse: 0.0097 - val_loss: 0.0545 - val_mse: 0.0091\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0552 - mse: 0.0094 - val_loss: 0.0596 - val_mse: 0.0112\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0549 - mse: 0.0094 - val_loss: 0.0566 - val_mse: 0.0093\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0546 - mse: 0.0091 - val_loss: 0.0545 - val_mse: 0.0095\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0553 - mse: 0.0096 - val_loss: 0.0583 - val_mse: 0.0107\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0553 - mse: 0.0098 - val_loss: 0.0542 - val_mse: 0.0095\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0549 - mse: 0.0095 - val_loss: 0.0533 - val_mse: 0.0088\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0545 - mse: 0.0092 - val_loss: 0.0555 - val_mse: 0.0099\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0548 - mse: 0.0097 - val_loss: 0.0550 - val_mse: 0.0099\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0545 - mse: 0.0093 - val_loss: 0.0533 - val_mse: 0.0086\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0552 - mse: 0.0096 - val_loss: 0.0565 - val_mse: 0.0101\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0554 - mse: 0.0098 - val_loss: 0.0576 - val_mse: 0.0102\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0547 - mse: 0.0094 - val_loss: 0.0565 - val_mse: 0.0088\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0542 - mse: 0.0089 - val_loss: 0.0545 - val_mse: 0.0098\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0551 - mse: 0.0096 - val_loss: 0.0556 - val_mse: 0.0099\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0539 - mse: 0.0089 - val_loss: 0.0531 - val_mse: 0.0090\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0552 - mse: 0.0096 - val_loss: 0.0562 - val_mse: 0.0099\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0547 - mse: 0.0093 - val_loss: 0.0576 - val_mse: 0.0103\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0554 - mse: 0.0096 - val_loss: 0.0578 - val_mse: 0.0106\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0550 - mse: 0.0096 - val_loss: 0.0557 - val_mse: 0.0094\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0544 - mse: 0.0093 - val_loss: 0.0548 - val_mse: 0.0098\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0547 - mse: 0.0093 - val_loss: 0.0564 - val_mse: 0.0100\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0551 - mse: 0.0098 - val_loss: 0.0540 - val_mse: 0.0093\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0548 - mse: 0.0096 - val_loss: 0.0542 - val_mse: 0.0097\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0548 - mse: 0.0095 - val_loss: 0.0549 - val_mse: 0.0096\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0549 - mse: 0.0095 - val_loss: 0.0560 - val_mse: 0.0085\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0561 - mse: 0.0100 - val_loss: 0.0541 - val_mse: 0.0095\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0555 - mse: 0.0099 - val_loss: 0.0561 - val_mse: 0.0102\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0549 - mse: 0.0097 - val_loss: 0.0529 - val_mse: 0.0090\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0553 - mse: 0.0096 - val_loss: 0.0543 - val_mse: 0.0095\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0548 - mse: 0.0096 - val_loss: 0.0556 - val_mse: 0.0091\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0545 - mse: 0.0092 - val_loss: 0.0568 - val_mse: 0.0100\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0543 - mse: 0.0090 - val_loss: 0.0577 - val_mse: 0.0107\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0543 - mse: 0.0090 - val_loss: 0.0531 - val_mse: 0.0091\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0540 - mse: 0.0089 - val_loss: 0.0517 - val_mse: 0.0082\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0527 - mse: 0.0084 - val_loss: 0.0508 - val_mse: 0.0077\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0521 - mse: 0.0081 - val_loss: 0.0556 - val_mse: 0.0097\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0537 - mse: 0.0089 - val_loss: 0.0524 - val_mse: 0.0079\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0534 - mse: 0.0088 - val_loss: 0.0517 - val_mse: 0.0084\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0518 - mse: 0.0080 - val_loss: 0.0578 - val_mse: 0.0110\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0525 - mse: 0.0083 - val_loss: 0.0533 - val_mse: 0.0091\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0532 - mse: 0.0087 - val_loss: 0.0520 - val_mse: 0.0079\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 4s 17ms/step - loss: 0.0523 - mse: 0.0083 - val_loss: 0.0511 - val_mse: 0.0078\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0523 - mse: 0.0083 - val_loss: 0.0535 - val_mse: 0.0093\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0518 - mse: 0.0080 - val_loss: 0.0512 - val_mse: 0.0079\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0513 - mse: 0.0079 - val_loss: 0.0539 - val_mse: 0.0093\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0518 - mse: 0.0081 - val_loss: 0.0542 - val_mse: 0.0097\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0511 - mse: 0.0078 - val_loss: 0.0487 - val_mse: 0.0068\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0515 - mse: 0.0079 - val_loss: 0.0576 - val_mse: 0.0096\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0511 - mse: 0.0078 - val_loss: 0.0510 - val_mse: 0.0072\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0508 - mse: 0.0077 - val_loss: 0.0517 - val_mse: 0.0078\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0511 - mse: 0.0078 - val_loss: 0.0546 - val_mse: 0.0098\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0517 - mse: 0.0081 - val_loss: 0.0521 - val_mse: 0.0078\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0501 - mse: 0.0074 - val_loss: 0.0519 - val_mse: 0.0074\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0504 - mse: 0.0075 - val_loss: 0.0509 - val_mse: 0.0077\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0501 - mse: 0.0074 - val_loss: 0.0495 - val_mse: 0.0072\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0507 - mse: 0.0077 - val_loss: 0.0542 - val_mse: 0.0080\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0521 - mse: 0.0082 - val_loss: 0.0535 - val_mse: 0.0094\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0501 - mse: 0.0074 - val_loss: 0.0538 - val_mse: 0.0083\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0501 - mse: 0.0075 - val_loss: 0.0491 - val_mse: 0.0069\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0496 - mse: 0.0073 - val_loss: 0.0574 - val_mse: 0.0110\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0509 - mse: 0.0078 - val_loss: 0.0521 - val_mse: 0.0080\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0506 - mse: 0.0077 - val_loss: 0.0519 - val_mse: 0.0075\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0497 - mse: 0.0073 - val_loss: 0.0497 - val_mse: 0.0070\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0496 - mse: 0.0073 - val_loss: 0.0468 - val_mse: 0.0064\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 4s 18ms/step - loss: 0.0498 - mse: 0.0074 - val_loss: 0.0482 - val_mse: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_12_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/WBmodels/wb60/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/WBmodels/wb60/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2  ...         5         6         7\n",
      "0  0.015532  0.522347  0.025777  ...  0.439456  0.029431  0.634098\n",
      "1  0.014979  0.522386  0.024840  ...  0.439570  0.028203  0.634203\n",
      "2  0.015475  0.522273  0.025652  ...  0.439233  0.029226  0.634038\n",
      "3  0.014566  0.522526  0.024113  ...  0.439770  0.027171  0.634426\n",
      "4  0.014274  0.522502  0.023575  ...  0.439887  0.026460  0.634603\n",
      "\n",
      "[5 rows x 8 columns]\n",
      "   063Volume  063Speed  051Volume  ...  031Speed  003Volume  003Speed\n",
      "0          1        99          3  ...        97          4        92\n",
      "1          1        99          3  ...        97          4        92\n",
      "2          1        99          3  ...        97          4        92\n",
      "3          1        99          3  ...        97          4        92\n",
      "4          1        99          3  ...        97          4        93\n",
      "\n",
      "[5 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10 #length of data used for the prediction, currently using the last 10 mins of data\n",
    "pre_len = 60 # distance of prediction, currently predicting speeds and volumes 30 mins from now\n",
    "\n",
    "train60X, train60Y,val60X,val60Y, test60X, test60Y = sequence_data_preparation(\n",
    "    seq_len, pre_len, train_data_t, val_data_t,test_data_t)\n",
    "\n",
    "optimizer2=keras.optimizers.Adam(learning_rate=.01)\n",
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=corrmatrix,\n",
    "    gc_layer_sizes=[16, 10],\n",
    "    gc_activations=[\"relu\", \"relu\"],\n",
    "    lstm_layer_sizes=[200, 200],\n",
    "    lstm_activations=[\"tanh\", \"tanh\"],\n",
    "    )\n",
    "x_input, x_output = gcn_lstm.in_out_tensors()\n",
    "model = Model(inputs=x_input, outputs=x_output)\n",
    "model.compile(optimizer=optimizer2, loss=\"mae\", metrics=[\"mse\"])\n",
    "history = model.fit(\n",
    "    train60X,\n",
    "    train60Y,\n",
    "    epochs=150,\n",
    "    batch_size=200,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(val60X, val60Y),\n",
    ")\n",
    "loss60 = history.history['val_loss'][149]\n",
    "tloss60 = history.history['loss'][149]\n",
    "model.save(\"WBmodels/wb60\")\n",
    "train_60pred = model.predict(train60X)\n",
    "test_60pred= model.predict(test60X)\n",
    "testloss60=mae(test60Y,test_60pred).numpy()\n",
    "\n",
    "test60pred_t = test_60pred.transpose()\n",
    "test_60preddf = pd.DataFrame(test_60pred)\n",
    "print(test_60preddf.head())\n",
    "unscaledoutput60 = pd.DataFrame(min_max_scaler.inverse_transform(test_60preddf))\n",
    "unscaledoutput60.columns = dataset.columns\n",
    "unscaledoutput60 = unscaledoutput60.astype(int)\n",
    "print(unscaledoutput60.head())\n",
    "unscaledoutput60.to_csv('predictions/wb60minpred.csv')\n",
    "test60Y_df = pd.DataFrame(test60Y)\n",
    "test60Y_unscaled = pd.DataFrame(min_max_scaler.inverse_transform(test60Y_df))\n",
    "test60Y_unscaled.columns=dataset.columns\n",
    "test60Y_unscaled = test60Y_unscaled.astype(int)\n",
    "test60Y_unscaled.to_csv('truths/wb60.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7fab8f1",
   "metadata": {
    "id": "oEawAD5oqla1"
   },
   "outputs": [],
   "source": [
    "losses_per_model = [loss5,loss10,loss15,loss30,loss45,loss60]\n",
    "with open(\"model_performances/wb_val_losses_time.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(str(item) for item in losses_per_model))\n",
    "tlosses_per_model = [tloss5,tloss10,tloss15,tloss30,tloss45,tloss60]\n",
    "with open(\"model_performances/wb_train_losses_time.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(str(item) for item in tlosses_per_model))\n",
    "test_losses_per_model = [testloss5,testloss10,testloss15,testloss30,testloss45,testloss60]\n",
    "with open(\"model_performances/wb_test_losses_time.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(str(item) for item in tlosses_per_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87f56c73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYdQCuyoqnEt",
    "outputId": "d1d938f2-a58b-4811-b383-e8de42b13303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/ (stored 0%)\n",
      "  adding: content/.config/ (stored 0%)\n",
      "  adding: content/.config/.last_update_check.json (deflated 22%)\n",
      "  adding: content/.config/configurations/ (stored 0%)\n",
      "  adding: content/.config/configurations/config_default (deflated 15%)\n",
      "  adding: content/.config/config_sentinel (stored 0%)\n",
      "  adding: content/.config/gce (stored 0%)\n",
      "  adding: content/.config/logs/ (stored 0%)\n",
      "  adding: content/.config/logs/2021.10.08/ (stored 0%)\n",
      "  adding: content/.config/logs/2021.10.08/13.45.08.864173.log (deflated 54%)\n",
      "  adding: content/.config/logs/2021.10.08/13.44.44.548229.log (deflated 86%)\n",
      "  adding: content/.config/logs/2021.10.08/13.44.50.952139.log (deflated 53%)\n",
      "  adding: content/.config/logs/2021.10.08/13.44.27.879250.log (deflated 54%)\n",
      "  adding: content/.config/logs/2021.10.08/13.45.09.534390.log (deflated 53%)\n",
      "  adding: content/.config/logs/2021.10.08/13.44.08.162145.log (deflated 91%)\n",
      "  adding: content/.config/active_config (stored 0%)\n",
      "  adding: content/.config/.last_survey_prompt.yaml (stored 0%)\n",
      "  adding: content/.config/.last_opt_in_prompt.yaml (stored 0%)\n",
      "  adding: content/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: content/predictions/ (stored 0%)\n",
      "  adding: content/predictions/wb5minpred.csv (deflated 80%)\n",
      "  adding: content/predictions/wb15minpred.csv (deflated 80%)\n",
      "  adding: content/predictions/wb60minpred.csv (deflated 78%)\n",
      "  adding: content/predictions/wb30minpred.csv (deflated 80%)\n",
      "  adding: content/predictions/wb45minpred.csv (deflated 81%)\n",
      "  adding: content/predictions/wb10minpred.csv (deflated 79%)\n",
      "  adding: content/WBmodels/ (stored 0%)\n",
      "  adding: content/WBmodels/wb5/ (stored 0%)\n",
      "  adding: content/WBmodels/wb5/assets/ (stored 0%)\n",
      "  adding: content/WBmodels/wb5/saved_model.pb (deflated 90%)\n",
      "  adding: content/WBmodels/wb5/variables/ (stored 0%)\n",
      "  adding: content/WBmodels/wb5/variables/variables.data-00000-of-00001 (deflated 5%)\n",
      "  adding: content/WBmodels/wb5/variables/variables.index (deflated 68%)\n",
      "  adding: content/WBmodels/wb5/keras_metadata.pb (deflated 91%)\n",
      "  adding: content/WBmodels/wb30/ (stored 0%)\n",
      "  adding: content/WBmodels/wb30/assets/ (stored 0%)\n",
      "  adding: content/WBmodels/wb30/saved_model.pb (deflated 90%)\n",
      "  adding: content/WBmodels/wb30/variables/ (stored 0%)\n",
      "  adding: content/WBmodels/wb30/variables/variables.data-00000-of-00001 (deflated 5%)\n",
      "  adding: content/WBmodels/wb30/variables/variables.index (deflated 68%)\n",
      "  adding: content/WBmodels/wb30/keras_metadata.pb (deflated 91%)\n",
      "  adding: content/WBmodels/wb10/ (stored 0%)\n",
      "  adding: content/WBmodels/wb10/assets/ (stored 0%)\n",
      "  adding: content/WBmodels/wb10/saved_model.pb (deflated 90%)\n",
      "  adding: content/WBmodels/wb10/variables/ (stored 0%)\n",
      "  adding: content/WBmodels/wb10/variables/variables.data-00000-of-00001 (deflated 6%)\n",
      "  adding: content/WBmodels/wb10/variables/variables.index (deflated 68%)\n",
      "  adding: content/WBmodels/wb10/keras_metadata.pb (deflated 91%)\n",
      "  adding: content/WBmodels/wb45/ (stored 0%)\n",
      "  adding: content/WBmodels/wb45/assets/ (stored 0%)\n",
      "  adding: content/WBmodels/wb45/saved_model.pb (deflated 89%)\n",
      "  adding: content/WBmodels/wb45/variables/ (stored 0%)\n",
      "  adding: content/WBmodels/wb45/variables/variables.data-00000-of-00001 (deflated 5%)\n",
      "  adding: content/WBmodels/wb45/variables/variables.index (deflated 68%)\n",
      "  adding: content/WBmodels/wb45/keras_metadata.pb (deflated 91%)\n",
      "  adding: content/WBmodels/wb60/ (stored 0%)\n",
      "  adding: content/WBmodels/wb60/assets/ (stored 0%)\n",
      "  adding: content/WBmodels/wb60/saved_model.pb (deflated 90%)\n",
      "  adding: content/WBmodels/wb60/variables/ (stored 0%)\n",
      "  adding: content/WBmodels/wb60/variables/variables.data-00000-of-00001 (deflated 5%)\n",
      "  adding: content/WBmodels/wb60/variables/variables.index (deflated 68%)\n",
      "  adding: content/WBmodels/wb60/keras_metadata.pb (deflated 91%)\n",
      "  adding: content/WBmodels/wb15/ (stored 0%)\n",
      "  adding: content/WBmodels/wb15/assets/ (stored 0%)\n",
      "  adding: content/WBmodels/wb15/saved_model.pb (deflated 90%)\n",
      "  adding: content/WBmodels/wb15/variables/ (stored 0%)\n",
      "  adding: content/WBmodels/wb15/variables/variables.data-00000-of-00001 (deflated 5%)\n",
      "  adding: content/WBmodels/wb15/variables/variables.index (deflated 68%)\n",
      "  adding: content/WBmodels/wb15/keras_metadata.pb (deflated 91%)\n",
      "  adding: content/truths/ (stored 0%)\n",
      "  adding: content/truths/wb45.csv (deflated 65%)\n",
      "  adding: content/truths/wb10.csv (deflated 65%)\n",
      "  adding: content/truths/wb15.csv (deflated 65%)\n",
      "  adding: content/truths/wb60.csv (deflated 65%)\n",
      "  adding: content/truths/wb5.csv (deflated 65%)\n",
      "  adding: content/truths/wb30.csv (deflated 65%)\n",
      "  adding: content/model_performances/ (stored 0%)\n",
      "  adding: content/model_performances/wb_val_losses_time.txt (deflated 40%)\n",
      "  adding: content/model_performances/wb_train_losses_time.txt (deflated 40%)\n",
      "  adding: content/model_performances/wb_test_losses_time.txt (deflated 40%)\n",
      "  adding: content/wbdataset.csv (deflated 76%)\n",
      "  adding: content/bradcorrmatrix.csv (deflated 67%)\n",
      "  adding: content/sample_data/ (stored 0%)\n",
      "  adding: content/sample_data/README.md (deflated 42%)\n",
      "  adding: content/sample_data/anscombe.json (deflated 83%)\n",
      "  adding: content/sample_data/mnist_train_small.csv (deflated 88%)\n",
      "  adding: content/sample_data/california_housing_test.csv (deflated 76%)\n",
      "  adding: content/sample_data/california_housing_train.csv (deflated 79%)\n",
      "  adding: content/sample_data/mnist_test.csv (deflated 88%)\n"
     ]
    }
   ],
   "source": [
    "#if running locally, files are written to the correct folders and this cell should be commented out\n",
    "#if running on google colab, zip file of notebook results will be downloaded. please extract into the project directory\n",
    "\n",
    "!zip -r /content/wboutputs.zip /content\n",
    "files.download(wboutputs.zip)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of wb_models_and_hyperparameter_tuning_MAPE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
